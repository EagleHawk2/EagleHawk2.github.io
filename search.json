[{"title":"Flink-Java | log4jè¯­æ³•","path":"/2024/08/13/flink-java-log4j/","content":"ä¸€ï¼‰log4jæ ¹é…ç½®è¯­æ³•example. 1log4j.rootLogger=[level],appenderName,appenderName,... explain. 1ï¼‰[level]è¡¨ç¤ºæ—¥å¿—ç­‰çº§ Log4jæ ¹æ®æ—¥å¿—ä¿¡æ¯çš„é‡è¦æˆéƒ½ï¼Œåˆ†OFFã€FATALã€ERRORã€WARNã€INFOã€DEBUGã€ALL Log4jå®˜æ–¹å»ºè®®å®é™…åº”ç”¨æƒ…å†µä¸‹ï¼Œåªä½¿ç”¨å››ä¸ªç­‰çº§ï¼Œä»é«˜åˆ°ä½ï¼šERRORã€WARNã€INFOã€DEBUG ERRORä¸ºä¸¥é‡é”™è¯¯ï¼Œä¸»è¦æ˜¯ç¨‹åºçš„é”™è¯¯ WARNä¸ºä¸€èˆ¬è­¦å‘Šï¼Œæ¯”å¦‚sessionä¸¢å¤± INFOä¸ºä¸€èˆ¬è¦æ˜¾ç¤ºä¿¡æ¯ï¼Œæ¯”å¦‚ç™»å½•ç™»å‡º DEBUGä¸ºç¨‹åºçš„è°ƒè¯•ä¿¡æ¯ æ ¹æ®æ—¥å¿—åˆ†çº§åˆ¶åº¦ï¼Œå¦‚æœå®šä¹‰çš„levelä¸ºINFOï¼ˆæ ‡å‡†ç¬¬ä¸‰ç­‰çº§ï¼‰ï¼Œé‚£ä¹ˆINFOä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—æ‰æ˜¾ç¤ºï¼Œè€ŒDEBUGæ—¥å¿—ä¸ä¼šæ˜¾ç¤º ä½¿ç”¨æ–¹å¼ 1log4j.rootLogger=[level] 2ï¼‰appenderNameè¡¨ç¤ºæ—¥å¿—ä¿¡æ¯è¾“å‡ºä½ç½®ï¼ˆç›®çš„åœ°ï¼‰ consoleè¡¨ç¤ºè¾“å‡ºåˆ°æ§åˆ¶å° Fileè¡¨ç¤ºå°†æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶ä¸­ DailyRollingFIleè¡¨ç¤ºæ¯å¤©äº§ç”Ÿä¸€ä¸ªæ—¥å¿—æ–‡ä»¶ RollingFIleè¡¨ç¤ºæ–‡ä»¶å¤§å°åˆ°è¾¾æŒ‡å®šå°ºå¯¸çš„æ—¶å€™äº§ç”Ÿä¸€ä¸ªæ–°çš„æ–‡ä»¶ Writerè¡¨ç¤ºå°†æ—¥å¿—ä¿¡æ¯ä»¥æµæ ¼å¼å‘é€åˆ°ä»»æ„æŒ‡å®šçš„åœ°æ–¹ ä½¿ç”¨æ–¹å¼ 1log4j.appender.appenderName = fully.qualified.name.of.appender.class 3ï¼‰é…ç½®æ—¥å¿—ä¿¡æ¯çš„æ ¼å¼ HTMLè¡¨ç¤ºä»¥HTMLæ ¼å¼å½¢å¼å¸ƒå±€ Patternè¡¨ç¤ºå¯ä»¥çµæ´»çš„æŒ‡å®šå¸ƒå±€æ¨¡å¼ Simpleè¡¨ç¤ºåŒ…å«æ—¥å¿—ä¿¡æ¯çš„çº§åˆ«å’Œä¿¡æ¯å­—ç¬¦ä¸² TTCCè¡¨ç¤ºæ—¥å¿—äº§ç”Ÿçš„æ—¶é—´ã€çº¿ç¨‹ã€ç±»åˆ«ç­‰ä¿¡æ¯ ä½¿ç”¨æ–¹å¼ 1log4j.appender.appenderName.layout = fully.qualified.name.of.layout.class","categories":["Flink"]},{"title":"Zookeeperæ­å»º","path":"/2024/04/25/zookeeper-build/","content":"Zookeeperé›†ç¾¤æ­å»ºè§£å‹æ–‡ä»¶#tar -zxvf zookeeper-3.4.5.tar.gz -C &#x2F;usr&#x2F;local&#x2F;src&#x2F; è§£å‹æ–‡ä»¶åˆ°\t&#x2F;usr&#x2F;local&#x2F;src&#x2F;\tç›®å½•ä¸‹ ä¿®æ”¹åå­—#mv zookeeper-3.4.5.tar.gz zookeepper ä¿®æ”¹åå­—ï¼Œæ–¹ä¾¿åæœŸé…ç½® é…ç½®ç¯å¢ƒå˜é‡#vi &#x2F;etc&#x2F;profile 123#zookeeper ENVexport ZOOKEEPER_HOME=/usr/local/src/zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/bin #sourc &#x2F;etc&#x2F;profile ä½¿æ–‡ä»¶ç”Ÿæ•ˆ é›†ç¾¤é…ç½®@æ–°å»ºdataæ–‡ä»¶#cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;zookeeper è¿›å…¥zookeeperæ–‡ä»¶å¤¹ #mdkir data æ–°å»ºdataæ–‡ä»¶å¤¹ @zoo.cfg#cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;zookeeper&#x2F;conf è¿›å…¥zookeeperä¸‹çš„confæ–‡ä»¶å¤¹ #cp zoo_sample.cfg zoo.cfg å¤åˆ¶æ ·æœ¬æ–‡ä»¶è¿›è¡Œä¿®æ”¹ ä¿®æ”¹å†…å®¹å¦‚ä¸‹ï¼Œæ³¨æ„ä¸“æ³¨ä¸€ä¸‹äº”ä¸ªå‚æ•°ï¼Œå…¶ä¸­dataDirä¸­çš„åœ°å€ä¸ºå‰ä¸€æ­¥ä¸­åœ¨zookeeperä¸‹å»ºç«‹çš„ 12345678tickTime=2000initLimit=10syncLimit=5dataDir=/usr/local/src/zookeeper/dataclientPort=2181server.1=master:2888:3888server.2=slave1:2888:3888server.3=slave2:2888:3888 name å«ä¹‰ tickTime tickç¿»è¯‘æˆä¸­æ–‡çš„è¯å°±æ˜¯æ»´ç­”æ»´ç­”çš„æ„æ€ï¼Œè¿èµ·æ¥å°±æ˜¯æ»´ç­”æ»´ç­”çš„æ—¶é—´ï¼Œå¯“æ„å¿ƒè·³é—´éš”ï¼Œå•ä½æ˜¯æ¯«ç§’ï¼Œç³»ç»Ÿé»˜è®¤æ˜¯2000æ¯«ç§’ï¼Œä¹Ÿå°±æ˜¯é—´éš”ä¸¤ç§’å¿ƒè·³ä¸€æ¬¡ã€‚å®¢æˆ·ç«¯ä¸æœåŠ¡å™¨æˆ–è€…æœåŠ¡å™¨ä¸æœåŠ¡å™¨ä¹‹é—´ç»´æŒå¿ƒè·³ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸ªtickTimeæ—¶é—´å°±ä¼šå‘é€ä¸€æ¬¡å¿ƒè·³ã€‚é€šè¿‡å¿ƒè·³ä¸ä»…èƒ½å¤Ÿç”¨æ¥ç›‘å¬æœºå™¨çš„å·¥ä½œçŠ¶æ€ï¼Œè¿˜å¯ä»¥é€šè¿‡å¿ƒè·³æ¥æ§åˆ¶Flowerè·ŸLeaderçš„é€šä¿¡æ—¶é—´ï¼Œé»˜è®¤æƒ…å†µä¸‹FLçš„ä¼šè¯æ—¶å¸¸æ˜¯å¿ƒè·³é—´éš”çš„ä¸¤å€ã€‚ initLimit é›†ç¾¤ä¸­çš„followeræœåŠ¡å™¨(F)ä¸leaderæœåŠ¡å™¨(L)ä¹‹é—´åˆå§‹è¿æ¥æ—¶èƒ½å®¹å¿çš„æœ€å¤šå¿ƒè·³æ•°ï¼ˆtickTimeçš„æ•°é‡ï¼‰ã€‚ syncLimit é›†ç¾¤ä¸­floweræœåŠ¡å™¨ï¼ˆFï¼‰è·Ÿleaderï¼ˆLï¼‰æœåŠ¡å™¨ä¹‹é—´çš„è¯·æ±‚å’Œç­”åº”æœ€å¤šèƒ½å®¹å¿çš„å¿ƒè·³æ•°ã€‚ dataDir è¯¥å±æ€§å¯¹åº”çš„ç›®å½•æ˜¯ç”¨æ¥å­˜æ”¾myidä¿¡æ¯è·Ÿä¸€äº›ç‰ˆæœ¬ï¼Œæ—¥å¿—ï¼Œè·ŸæœåŠ¡å™¨å”¯ä¸€çš„IDä¿¡æ¯ç­‰ã€‚ clientPort å®¢æˆ·ç«¯è¿æ¥çš„æ¥å£ï¼Œå®¢æˆ·ç«¯è¿æ¥zookeeperæœåŠ¡å™¨çš„ç«¯å£ï¼Œzookeeperä¼šç›‘å¬è¿™ä¸ªç«¯å£ï¼Œæ¥æ”¶å®¢æˆ·ç«¯çš„è¯·æ±‚è®¿é—®ï¼è¿™ä¸ªç«¯å£é»˜è®¤æ˜¯2181ã€‚ @å†™å…¥èŠ‚ç‚¹ä¿¡æ¯#cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;zookeeper&#x2F;data è¿›å…¥æ–°å»ºçš„dataæ–‡ä»¶å¤¹ä¸­ ï¼ˆå½“ç„¶è¿™ä¸€æ­¥æœ€å¥½å…ˆå¤åˆ¶åå†è¿›è¡Œï¼Œä»¥å…åœ¨åˆ†èŠ‚ç‚¹ä¸­æ²¡æœ‰èŠ‚ç‚¹ä¿¡æ¯ï¼‰ ä½¿ç”¨echoè¯­å¥æŠŠèŠ‚ç‚¹ä¿¡æ¯1ã€2ã€3åˆ†åˆ«å†™å…¥ä¸‰ä¸ªèŠ‚ç‚¹çš„dataç›®å½•ä¸­ åœ¨masterèŠ‚ç‚¹ä¸­ #echo 1 &gt; myid åœ¨slave1èŠ‚ç‚¹ä¸­ #echo 2 &gt; myid åœ¨slave2èŠ‚ç‚¹ä¸­ #echo 3 &gt; myid æ‹·è´ç¯å¢ƒ#scp -r &#x2F;usr&#x2F;local&#x2F;src&#x2F;zookeeper slave1:&#x2F;usr&#x2F;local&#x2F;src&#x2F; #scp -r &#x2F;usr&#x2F;local&#x2F;src&#x2F;zookeeper slave2:&#x2F;usr&#x2F;local&#x2F;src&#x2F; å¯åŠ¨é›†ç¾¤#cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;zookeeper&#x2F;bin è¿›å…¥åˆ°zookeeperçš„binç›®å½•ä¸‹ #.&#x2F;zkServer.sh start å¯åŠ¨zookeeper #.&#x2F;zkServer.sh status æŸ¥çœ‹zookeeperçŠ¶æ€ #.&#x2F;zkCli.sh å¯åŠ¨Cliï¼Œè¿æ¥åˆ°zookeeperæœåŠ¡å™¨ #.&#x2F;zkServer.sh stop åœæ­¢zookeeperæœåŠ¡å™¨ å…³äºZookeeperçš„æŠ¥é”™ä¿¡æ¯é—®é¢˜ä¸€å…³äºzookeeperçš„é…ç½®ï¼Œç”±äºæ²¡æœ‰è¿‡å¤šçš„é…ç½®å› ç´ ï¼Œåœ¨æ£€æŸ¥æŠ¥é”™ä¿¡æ¯æ—¶ï¼Œåªèƒ½é€šè¿‡æ’æŸ¥æ—¥å¿—æ–‡ä»¶æ¥è¿›è¡ŒæŠ¥é”™çš„ä¿®æ”¹ï¼Œç›®å‰å‡ºç°çš„é—®é¢˜ä¸€æ˜¯zookeeperæ— æ³•å¯åŠ¨ï¼Œåœ¨è¾“å…¥**#.&#x2F;zkServer.sh start**åï¼Œå¯åŠ¨å¤±è´¥ï¼Œæ­¤é—®é¢˜ç°è±¡ï¼š å¯åŠ¨zkå¤±è´¥ï¼Œä½†æ˜¯åœ¨å¯åŠ¨**#.&#x2F;zkServer.sh start**æ—¶ï¼Œä¸ä¼šæŠ¥é”™ï¼Œæ­£å¸¸æ˜¾ç¤ºã€‚ jpsæŸ¥è¯¢æ—¶ï¼Œæ­£å¸¸æ˜¾ç¤º**#QuorumPeerMain** #.&#x2F;zkServer.sh statusæŸ¥è¯¢æ—¶ï¼Œæ˜¾ç¤ºæŠ¥é”™ï¼ŒæŠ¥é”™ä¿¡æ¯å¦‚ä¸‹ï¼š æŠ¥é”™ä¿¡æ¯ #.&#x2F;zkServer.sh stopå…³é—­é›†ç¾¤æ—¶ï¼Œä¸»èŠ‚ç‚¹æ— æ³•å…³é—­çš„æŠ¥é”™ è§£å†³åŠæ³•ï¼š åœ¨zoo.cfgæ–‡ä»¶ä¸­ï¼ŒåŸæœ¬ç‰ˆæœ¬ä¸­ï¼ŒæŸ¥è¯¢åˆ°çš„æ˜¯zoo.cfgæ–‡ä»¶ä¸­æ— æ³•è¯†åˆ«ipåœ°å€ï¼Œæ•…å†™æ³•ä¸ºï¼š 123server.1=master:2888:3888server.2=slave1:2888:3888server.3=slave2:2888:3888 æŸ¥è¯¢æ—¥å¿—å‘ç°ï¼ŒæŠ¥é”™ä¿¡æ¯ä¸ºï¼š æŠ¥é”™ä¿¡æ¯ æ˜¾ç¤ºaddress already in useï¼Œé‚£å°±è€ƒè™‘æ˜¯å¦ipåæ— æ³•è¯†åˆ«ï¼Œéœ€è¦ä½¿ç”¨ipåœ°å€ æ•…è¿›è¡Œä¿®æ”¹zoo.cfgä¸­ipåä¸ºipåœ°å€ 123server.1=192.168.100.3:2888:3888server.2=192.168.100.4:2888:3888server.3=192.168.100.2:2888:3888","categories":["Zookeeper"]},{"title":"Sparkæ­å»º","path":"/2024/04/25/spark-build/","content":"SparkSpark Local1tar -zxvf /opt/software/spark.tar.gz -C /opt/module ç›´æ¥è§£å‹å³å¯ä½¿ç”¨ 1bin/run-example SparkPi 10 æ‰§è¡ŒSparkPiæ¡ˆä¾‹ï¼Œä½¿ç”¨binå†…ç½®çš„run-exampleæ–¹æ³• Spark Standalone12345vi spark-env.shexport SPARK_MASTER_IP=masterexport SPARK_MASTER_PORT=7077export SPARK_WORKER_CORES=1export SPARK_WORKER_MEMORY=3g å¯ä»¥æ ¹æ®æ–‡ä»¶ä¸­çš„æç¤ºæ¥è‡ªè¡Œé…ç½®æ‰€éœ€å†…å®¹ 1234vi workersmasterslave1slave2 12vi sbin/spark-config.shexport JAVA_HOME=/opt/module/jdk åœ¨sbinç›®å½•ä¸‹è¦åŠ å…¥jdkè·¯å¾„ï¼Œé˜²æ­¢JAVAç›¸å…³æŠ¥é”™ 1234bin/spark-submit \\--class org.apache.spark.examples.SparkPi \\--master spark://master:7077 \\example/jars/spark-examles_2.12-3.3.0.jar 10 æ‰§è¡Œæ¡ˆä¾‹ Spark on Yarnè§£å‹æ–‡ä»¶ 1tar -zxvf /opt/software/spark -C /opt/module/ @é…ç½®ç¯å¢ƒ1234vi /etc/profileexport SPARK_HOME=/opt/module/sparkexport PATH=$PATH:$SPARK_HOME/binsource /etc/profile @é…ç½®æ–‡ä»¶#spark-config.sh(sbin)12vi /opt/module/spark/sbin/spark-config.shexport JAVA_HOME=/opt/module/jdk æ³¨æ„è¿™é‡Œæ˜¯è¿›å…¥sbinç›®å½•ä¸‹çš„spark-config.shä¸­è¿›è¡Œé…ç½®jdk #spark-env.sh12345678cp spark-env.sh.template spark-env.shvi /opt/module/spark/conf/spark-env.shexport JAVA_HOME=/opt/module/jdkexport SPARK_HOME=/opt/module/sparkexport SPARK_LOCAL_DIR=$&#123;SPARK_HOME&#125;/tmp#on yarné…ç½®export HADOOP_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoopexport YARN_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop SPARK_LOCAL_DIRé…ç½®çš„è·¯å¾„ä¸ºsparkçš„tmpç›®å½•ï¼› HADOOP_CONF_DIRé…ç½®çš„è·¯å¾„ä¸ºhadoopçš„confï¼ˆhadoopä¸‹çš„etc&#x2F;hadoopï¼‰ YARN_CONF_DIRé…ç½®çš„è·¯å¾„ä¸ºhadoopçš„confï¼ˆhadoopä¸‹çš„etc&#x2F;hadoopï¼‰ #workers123vi /opt/module/spark/workersslave1slave2 åŒæ ·çš„ï¼Œè¿™ä¸ªæ–‡ä»¶å¯¹åº”è€ç‰ˆæœ¬çš„slavesæ–‡ä»¶ï¼Œæ–°ç‰ˆé—®ä¸ºworkersï¼Œé…ç½®å†…å®¹ç›¸åŒ #yarn-site.xmlåœ¨hadoop&#x2F;etc&#x2F;hadoopä¸‹ spark on yarné…ç½®æ—¶ï¼Œéœ€è¦åœ¨hadoopä¸‹çš„yarnæ–‡ä»¶ä¸­æ·»åŠ ä¸¤è¡Œé…ç½®ï¼Œåœ¨hadoopä¸­æœ‰è®²è§£ 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; å¯åŠ¨ä¸ä½¿ç”¨@åˆ†å‘èŠ‚ç‚¹ä¸å¯åŠ¨é›†ç¾¤#åˆ†å‘èŠ‚ç‚¹12345scp -r /opt/module/spark slave1:/opt/modulescp -r /opt/module/spark slave2:/opt/modulescp -r /etc/profile slave1:/etc/scp -r /etc/profile slave2:/etc/source /etc/profile #å¯åŠ¨é›†ç¾¤1start-all.sh @Spark Shell#è¿›å…¥shell1spark shell #è¿è¡Œæ¶åŒ…1spark-submit --master yarn --class org.apache.spark.examples.SparkPi $SPARK_HOME/examples/jars/spark-examples_2.12-3.1.1.jar","categories":["Spark"]},{"title":"Redisæ­å»º","path":"/2024/04/25/redis-build/","content":"Redisè§£å‹æ–‡ä»¶ 1tar -zxvf /opt/software/redis.tar.gz -C /opt/module/ æŸ¥çœ‹Linuxç³»ç»Ÿæœ‰æ²¡æœ‰gccç¯å¢ƒ 1gcc -version å®‰è£…gcc 1yum install gcc-c++ ç¼–è¯‘redis 12cd /opt/module/redis-6.2.6make å®‰è£…redis 1make install PREFIX=/opt/module/redis-6.2.6 æ‹·è´conf 1cp redis.conf /opt/moduele/redis-6.2.6/bin å¯åŠ¨redis å‰å°å¯åŠ¨ 1./bin/redis-server redis.conf ç›´æ¥è¿è¡Œçš„æ—¶å€™è®¾ç½®å‚æ•° 1./bin/redis-server --port 6388 åå°å¯åŠ¨ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ å¤‡ä»½ redis.conf , æ‹·è´ä¸€ä»½ redis.conf åˆ°å…¶ä»–ç›®å½•ã€‚ å¦‚è®©åœ¨ &#x2F;etc ç›®å½•ä¸‹ï¼Œcp redis.conf &#x2F;etc&#x2F;redis.confä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œ å°† daemonize no æ”¹æˆ yesï¼Œ è®©æœåŠ¡åœ¨åå°å¯åŠ¨redis åå°å¯åŠ¨ï¼š redis-server &#x2F;etc&#x2F;redis.conf å°†å¯åŠ¨å›ºå®šä¸ºå¯åŠ¨å‘½ä»¤ 1234567891011121314# cat /usr/lib/systemd/system/redis.service[Unit]Description=RedisAfter=syslog.target network.target remote-fs.target nss-lookup.target [Service]Type=forkingPIDFile=/run/redis_6379.pidExecStart=/usr/local/redis-6.2.4/src/redis-server /usr/local/redis-6.2.4/redis.confExecStop=/bin/kill -s QUIT $MAINPIDPrivateTmp=true [Install]WantedBy=multi-user.target æŸ¥çœ‹redisè¿›ç¨‹ 1ps -ef | grep redis","categories":["Redis"]},{"title":"CentOSä¸å¤§æ•°æ®é›†ç¾¤æ­å»ºæ€è·¯","path":"/2024/04/25/linux-build/","content":"å‰è¨€æœ¬ç« è®²è§£çš„æ˜¯åœ¨æ­å»ºHadoopç”Ÿæ€ç³»ç»Ÿå‰éœ€è¦çš„ä¸€äº›æ€è·¯å’Œæ¡ä»¶ï¼Œå†…å®¹å†—ä½™ï¼Œå¤šæ˜¯äº›åæ§½çš„è¯ï¼Œå¤§æ¦‚çœ‹çœ‹å†…å®¹æ˜¯å¦éƒ½å·²ç»é…ç½®äº†å³å¯ã€‚ Hadoop ç”Ÿæ€æ˜¯å­¦ä¹ å¤§æ•°æ®çš„é‡ä¸­ä¹‹é‡ï¼Œè™½ç„¶æˆ‘ç†è§£ä¸æ·±ï¼Œä½†æ˜¯å…³äºhadoopæ‰€è¡ç”Ÿå‡ºçš„apacheçš„é¡¶çº§å¼€æºé¡¹ç›®ï¼Œéƒ½æ˜¯å›´ç»•ç€hadoopè€Œè¿›è¡Œä½¿ç”¨çš„ï¼Œæ‰€ä»¥è¦æƒ³ä½¿ç”¨apacheçš„å…¶ä»–é¡¶çº§é¡¹ç›®ï¼Œé¦–å…ˆè¦ç†è§£çš„å°±æ˜¯å…³äºHadoopçš„ä¸€äº›çŸ¥è¯†ã€‚ ç”±äºæˆ‘åœ¨å­¦ä¹ çš„æ—¶å€™ï¼Œæ˜¯é‡‡ç”¨å®ä¾‹å¼å­¦ä¹ ï¼Œäºæ˜¯ä¹ï¼Œå…ˆæ˜¯ä¼šç”¨ï¼Œæ‰æ˜¯ç†è§£é¡¹ç›®ï¼Œæ‰€ä»¥æœ‰å¾ˆå¤šä¸œè¥¿ï¼Œæ˜¯è‡ªå·±çš„ç†è§£ï¼Œä¸èƒ½å’ŒçœŸæ­£çš„å­¦é™¢æ´¾ç›¸åª²ç¾ï¼Œæ‰€ä»¥æ­¤æ–‡ç« æ›´å¤šçš„æ˜¯ç”¨äºè‡ªå·±æ­å»ºè®­ç»ƒçš„æ—¶å€™ä½¿ç”¨ï¼Œä¸€äº›é—®é¢˜ä¹Ÿæ˜¯ç›¸å…³ä¸è‡ªèº«é—®é¢˜è€Œæ’°å†™ï¼Œåˆ†é—¨åˆ«ç±»ï¼Œå„ä½è¯»è€…å„å–æ‰€éœ€å³å¯ ï¼ˆEagleHawk 2023.6.28ï¼‰ å‰ç½®å®‰è£…æ­å»ºè§„åˆ’å†™åœ¨æœ€å‰â€”â€”æ˜¯å› ä¸ºå†™åˆ°ç¬¬ä¸‰ç‚¹äº†ï¼Œç»“æœå‘ç°è§„åˆ’åº”è¯¥æ˜¯ååœ¨æ‰€æœ‰æ­¥éª¤ä¹‹å‰çš„ï¼Œå¥½å§åªèƒ½å†™åœ¨æœ€å‰äº†TAT å¦‚ä½•è§„åˆ’é›†ç¾¤æ­å»ºï¼š é¦–å…ˆè¦äº†è§£hadoopçš„å·¥ä½œåŸç†ã€‚ hadoopæœ‰å¾ˆå¤šå­é¡¹ç›®ï¼Œåœ¨è§„åˆ’æ—¶ï¼Œæˆ‘ï¼ˆä¸ªäººå“ˆo(ï¿£â–½ï¿£)ãƒ–ï¼‰åªè€ƒè™‘ä¸¤ä¸ªæ¨¡å—ï¼Œä¸€ä¸ªæ˜¯HDFSåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼Œå¦ä¸€ä¸ªæ˜¯MapReduceåˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶ã€‚è¿™ä¸¤ä¸ªå­é¡¹ç›®æ˜¯hadoopå½“ä¸­ç›¸å½“åƒèµ„æºçš„ä¸¤ä¸ªé¡¹ç›®ï¼Œæ‰€ä»¥ä¸€èˆ¬æ˜¯éœ€è¦è®²è¿™ä¸¤ä¸ªæ¨¡å—éƒ¨ç½²åœ¨ä¸åŒçš„èŠ‚ç‚¹ä¸Šé¢ï¼ˆå³ï¼Œhdfséƒ¨ç½²åœ¨ä¸€å°è™šæ‹Ÿæœºä¸Šï¼Œmapreduceéƒ¨ç½²åœ¨ä¸€å°è™šæ‹Ÿæœºä¸Šï¼‰ã€‚ ä»¥ä¸Šï¼Œå°±æ˜¯ç®€å•çš„æ­å»ºè§„åˆ’äº†ï¼Œåœ¨æ­å»ºè§„åˆ’æ—¶ï¼Œæˆ‘ä»¬è¿˜éœ€è¦è§„åˆ’ipåï¼Œipåœ°å€ç­‰ï¼Œè¿™é‡Œå°±ä¸èµ˜è¿°äº†ï¼Œç›´æ¥å®æ“å°±èƒ½ç†è§£ï¼ˆå¥½å§ï¼Œå› ä¸ºæˆ‘ä¹Ÿæ˜¯å®æ“ç»ƒå‡ºæ¥çš„â€¦æ‹³æ‰“ç™¾éï¼Œå…¶æ„è‡ªç°å˜›hhhï¼‰ä»¥ä¸‹ï¼Œæ˜¯ä¸ªäººçš„éƒ¨åˆ†ç†è§£ã€‚ HDFSå­˜å‚¨æ¶æ„ä¸‹ï¼Œæœ‰ä¸‰ä¸ªè¿›ç¨‹ï¼šNameNodeï¼ŒDataNodeï¼ŒSecondaryNameNode MapReduceè®¡ç®—æ¡†æ¶ä¸‹ï¼Œæœ‰ä¸¤ä¸ªè¿›ç¨‹ï¼šResourceMangerï¼ŒNodeManager å…¶ä¸­SecondaryNameNodeå’ŒResourceMangeréƒ½æ˜¯å èµ„æºçš„å¤§æˆ·ï¼Œæ‰€ä»¥ä¸€èˆ¬æ¥è¯´ï¼Œä¼šå°†è¿™ä¸¤ä¸ªè¿›ç¨‹éƒ¨ç½²åœ¨ä¸åŒçš„èŠ‚ç‚¹ï¼Œä½œä¸ºå®Œå…¨åˆ†å¸ƒå¼çš„éƒ¨ç½²ã€‚å¦‚æœå°†æ‰€æœ‰è¿›ç¨‹éƒ½éƒ¨ç½²åœ¨ç›¸åŒèŠ‚ç‚¹ä¸‹ï¼Œåˆ™æ˜¯ä¼ªåˆ†å¸ƒå¼çš„å®‰è£…é…ç½®ã€‚ èŠ‚ç‚¹åç§° IPè§„åˆ’ åˆ†å¸ƒå¼è§„åˆ’ master 192.168.xx.xx NameNodeã€DataNode slave1 192.168.xx.xx SecondaryNameNode slave2 192.168.xx.xx ResourceManager åˆ†æå¥½äº†èŠ‚ç‚¹åˆ†å¸ƒï¼Œé‚£ä¹ˆå°±å¯ä»¥å¼€å§‹éƒ¨ç½²ç¯å¢ƒäº†â€”â€”(à¸‡ â€¢_â€¢)à¸‡ ç¯å¢ƒæ¡ä»¶ åç§° åª’ä»‹ ç‰ˆæœ¬ å¤‡æ³¨ Linux è™šæ‹Ÿæœº CentOS7 3å°ï¼ˆå› ä¸ºæ­å»ºçš„æ˜¯é›†ç¾¤ï¼Œæ‰€ä»¥éœ€è¦ä¸‰å°è™šæ‹Ÿæœºï¼‰ jdk tar.gzå‹ç¼©åŒ… jdk-8u212-linux-x64.tar.gz jdkç‰ˆæœ¬éœ€è¦å¯¹åº”ï¼Œå¯ä»¥è¿›apcheå®˜ç½‘æŸ¥çœ‹ hadoop tar.gzå‹ç¼©åŒ… hadoop-3.1.3.tar.gz zookeeper tar.gzå‹ç¼©åŒ… apache-zookeeper-3.5.7-bin.tar.gz zookeeperåœ¨é…ç½®HadoopHAæ—¶éœ€è¦ä½¿ç”¨ åœ¨hadoop3.1.3ç‰ˆæœ¬ä¹‹å‰ï¼Œæˆ‘è¿›è¡Œè¿‡hadoop2.7ç‰ˆæœ¬çš„æ­å»ºï¼Œç›¸æ¯”ä¹‹ä¸‹ï¼Œhadoopç‰ˆæœ¬æ›´æ”¹äº†ä¸€äº›é…ç½®æ–‡ä»¶ï¼ŒåŒæ—¶ä¹Ÿå¢åŠ äº†ä¸€äº›éœ€è¦é…ç½®çš„å†…å®¹ï¼Œåœ¨ä¸‹æ–‡ä¸­ä¼šè¯¦ç»†è¿›è¡Œç®€è¿°ï¼Œä½†æ˜¯å¤§å·®ä¸å·®ï¼Œæ‰€æœ‰çš„é…ç½®éƒ½æœ‰å†…éƒ¨çš„æ ¸å¿ƒæ–‡ä»¶ä¸å‚æ•°ï¼Œæ›´æ”¹è¿™äº›æ ¸å¿ƒå‚æ•°ï¼Œå°±æ˜¯é›†ç¾¤æ­å»ºçš„æ ¸å¿ƒã€‚ è™šæ‹Ÿæœºåœ¨é…ç½®å¼€å§‹å‰ï¼Œéœ€è¦å¯¹æ¯ä¸€å°è™šæ‹Ÿæœºåšä¸‰ä¸ªæ–‡ä»¶çš„äº†è§£æˆ–æ˜¯é…ç½® hostname 1234vi /etc/hostnamemasterslave1slave2 æ­¤æ–‡ä»¶å­˜å‚¨ç€æœ¬æœºçš„ipåï¼Œå¯ä»¥è¿›è¡Œä¿®æ”¹ï¼Œä¿®æ”¹æ–¹å¼æŒ‰ç…§è§„åˆ’é›†ç¾¤æ¥è¿›è¡Œä¿®æ”¹ï¼Œä¸»èŠ‚ç‚¹masterï¼Œåˆ†èŠ‚ç‚¹slave1ï¼Œslave2ã€‚ ifcfg-ens33 1vi /etc/sysconfig/network-script/ifcfg-ens33 TYPE&#x3D;â€Ethernetâ€ï¼ˆç½‘ç»œç±»å‹ï¼šè‹±ç‰¹ç½‘ï¼‰BOOTPROTO&#x3D;â€staticâ€ï¼ˆç½‘ç»œé…ç½®å‚æ•°ï¼šé™æ€IP&#x2F;dhcp åŠ¨æ€IP&#x2F;none æ— ï¼‰NAME&#x3D;â€ens33â€ï¼ˆç½‘ç»œå±äºç½‘å¡ï¼šens33ï¼‰DEVICE&#x3D;â€ens33â€ï¼ˆç½‘ç»œåç§°ï¼šens33ï¼‰ONBOOT&#x3D;â€yesâ€ï¼ˆå¼€æœºè‡ªå¯åŠ¨ï¼šyes&#x2F;noï¼‰IPADDR&#x3D;â€192.168.48.200â€ï¼ˆæœ¬æœºIPï¼‰PREFIX&#x3D;â€24â€ï¼ˆå­ç½‘æ©ç çš„ä½æ•°ï¼‰GATEWAY&#x3D;â€192.168.48.2â€ï¼ˆç½‘å…³ï¼‰DNS1&#x3D;â€192.168.48.2â€ï¼ˆåŸŸåï¼‰ è¿™ä¸ªæ–‡ä»¶æ˜¯å­˜å‚¨æœ¬æœºipåœ°å€çš„æ–‡ä»¶ï¼Œåœ¨ä¸åŒçš„ç‰ˆæœ¬ä¸­ï¼Œå­˜å‚¨ä½ç½®ä¹Ÿä¼šæœ‰å˜åŠ¨ï¼Œç›®å‰æˆ‘è§è¿‡çš„å­˜å‚¨ä½ç½®å°±ä¸¤ä¸ªæ–‡ä»¶ï¼Œè¿™ä¸ªæ–‡ä»¶æ˜¯OS7å½“ä¸­çš„å­˜å‚¨ä½ç½®ï¼Œä¿®æ”¹ipå³åœ¨æ­¤æ–‡ä»¶ä¸­è¿›è¡Œä¿®æ”¹ã€‚ æŸ¥è¯¢ipåœ°å€ä¹Ÿå¯ä»¥ç”¨ä»¥ä¸‹æŒ‡ä»¤ã€‚ æŸ¥è¯¢ip 12ip addrifconfig å¦‚æœç¬¬äºŒæ¡æŒ‡ä»¤æŠ¥é”™ä¸ºæœªå®‰è£…å·¥å…·åŒ…ï¼Œå®‰è£…å‘½ä»¤ å®‰è£…net-toolså·¥å…·åŒ… 1yum -y install net-tools hosts 1234vi /etc/hosts192.168.xx.xxx master192.168.xx.xxx slave1192.168.xx.xxx slave2 å­˜æ”¾å„ä¸ªèŠ‚ç‚¹æ˜ å°„ï¼Œipåä¸ºæœ¬æœºipåï¼Œipåœ°å€ä¸ºæœ¬æœºipåœ°å€ã€‚ æ³¨æ„ ä¿®æ”¹å®Œä¸Šè¿°æ–‡ä»¶åï¼Œéœ€è¦é‡å¯ç½‘ç»œæœåŠ¡ï¼Œé‡å¯æœºå™¨ é‡å¯ç½‘ç»œæœåŠ¡ 1service network restart é‡å¯æœºå™¨ 1reboot é˜²ç«å¢™å…³äºé˜²ç«å¢™çš„é—®é¢˜ï¼Œåœ¨è¿›è¡Œé›†ç¾¤æ­å»ºçš„æ—¶å€™ï¼Œé˜²ç«å¢™æ˜¯ä¸€å®šéœ€è¦å…³é—­çš„ä¸œè¥¿ã€‚å› ä¸ºæ­å»ºçš„é›†ç¾¤éƒ½æ˜¯å†…ç½‘æ­å»ºçš„ï¼Œå¯¹å¤–è¿˜æœ‰ä¸€ä¸ªæœåŠ¡å™¨ï¼Œé‚£ä¸ªæœåŠ¡å™¨æœ‰é˜²ç«å¢™ï¼Œç”±å®ƒæ¥è®¿é—®å†…ç½‘é›†ç¾¤ï¼Œå¦‚æœå†…ç½‘å†…å¼€å¯é˜²ç«å¢™ï¼Œå†…ç½‘é›†ç¾¤é€šè®¯ä¼šå‡ºç°å¾ˆå¤šé—®é¢˜ã€‚å…³é—­é˜²ç«å¢™ï¼Œä¸€åŠ³æ°¸é€¸ï¼ è¿™æ˜¯åœ¨æµ‹è¯•ç¯å¢ƒä¸‹éœ€è¦å…³é—­é˜²ç«å¢™ï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒç›®å‰è¿˜æ²¡æœ‰è¿›è¡Œè¿‡ç”Ÿäº§ï¼Œæ‰€ä»¥åªé’ˆå¯¹ä¸å½“å‰æµ‹è¯•ç‰ˆæœ¬ å¦å¤–ï¼Œä»¥ä¸‹shellä»£ç éƒ½æ˜¯åœ¨CentOS7ç‰ˆæœ¬ä¸‹çš„shellå‘½ä»¤ï¼Œå¦‚æœç‰ˆæœ¬ä¸åŒï¼Œè¯·ç§»æ­¥baidu.com æŸ¥çœ‹é˜²ç«å¢™çŠ¶æ€ 1systemctl status firewalld æš‚æ—¶å…³é—­é˜²ç«å¢™ 1systemctl stop firewalld æ°¸ä¹…å…³é—­é˜²ç«å¢™ 1systemctl disable firewalld é‡å¯é˜²ç«å¢™ 1systemctl enabled firewalld SSHSSHæ˜¯ä¸€ç§åŠ å¯†çš„ç½‘ç»œä¼ è¾“åè®®ï¼Œå¯ä»¥åœ¨ä¸å®‰å…¨çš„ç½‘ç»œä¸­ä¸ºç½‘ç»œæœåŠ¡æä¾›å®‰å…¨çš„ä¼ è¾“ç¯å¢ƒã€‚SSHé€šè¿‡åœ¨ç½‘ç»œä¸­å»ºç«‹å®‰å…¨éš§é“æ¥å®ç°SSHå®¢æˆ·ç«¯ä¸æœåŠ¡å™¨ä¹‹é—´çš„è¿æ¥ã€‚SSHæœ€å¸¸è§çš„ç”¨é€”æ˜¯è¿œç¨‹ç™»å½•ç³»ç»Ÿï¼Œäººä»¬é€šå¸¸åˆ©ç”¨SSHæ¥ä¼ è¾“å‘½ä»¤è¡Œç•Œé¢å’Œè¿œç¨‹æ‰§è¡Œå‘½ä»¤ã€‚SSHä½¿ç”¨é¢‘ç‡æœ€é«˜çš„åœºåˆæ˜¯ç±»Unixç³»ç»Ÿï¼Œä½†æ˜¯Windowsæ“ä½œç³»ç»Ÿä¹Ÿèƒ½æœ‰é™åº¦åœ°ä½¿ç”¨SSHã€‚2015å¹´ï¼Œå¾®è½¯å®£å¸ƒå°†åœ¨æœªæ¥çš„æ“ä½œç³»ç»Ÿä¸­æä¾›åŸç”ŸSSHåè®®æ”¯æŒï¼ŒWindows 10 1803ç‰ˆæœ¬å·²æä¾›OpenSSHå·¥å…·ã€‚åœ¨è®¾è®¡ä¸Šï¼ŒSSHæ˜¯Telnetå’Œéå®‰å…¨shellçš„æ›¿ä»£å“ã€‚ é€šè¿‡SSH Clientæˆ‘ä»¬å¯ä»¥è¿æ¥åˆ°è¿è¡Œäº†SSH Serverçš„è¿œç¨‹æœºå™¨ä¸Šã€‚ è€Œæ¯å°æœºå™¨éƒ½å¯ä»¥ç”Ÿæˆè‡ªå·±çš„å®‰å…¨å¯†é’¥ï¼Œè€Œæˆ‘ä»¬åœ¨æ­å»ºé›†ç¾¤æ—¶ï¼Œä¸ºäº†æ–¹ä¾¿sshçš„æœåŠ¡åˆ‡æ¢ï¼Œä¼šè¿›è¡Œsshçš„å…å¯†ç™»å½•ã€‚ä»¥æ­¤æ¥å¿«é€Ÿè¿›è¡ŒSSH Serveråˆ‡æ¢ã€‚ å¦‚æœä¸è€ƒè™‘ç‰¹æ®Šæƒ…å†µï¼Œå¯ä»¥ç›´æ¥çœ‹å…å¯†ç™»å½•çš„æ–¹å¼ï¼Œå…¶ä»–ä½œä¸ºäº†è§£å³å¯ã€‚ æŸ¥çœ‹SSHæœåŠ¡æ˜¯å¦å¯åŠ¨ 1systemctl status sshd @Action:active(running)SHHè¿è¡Œä¸­ @Connection refusedSSHæœªå®‰è£… å¯åŠ¨SSHæœåŠ¡ 1systemctl start sshd å®‰è£…OpenSSH Server 1sudo apt-get install openssh-server æ¥ä¸‹æ¥ä»‹ç»SSH Clientå…¬å…±å¯†é’¥ç™»å½•ï¼Œå…¶ä¸­ï¼Œ-p portä¸ºç›‘å¬çš„ç«¯å£å·ï¼Œä¸€èˆ¬ä¸º22ï¼Œå¦‚æœä¸º22ï¼Œå¯çœç•¥ï¼›userä¸ºç”¨æˆ·åï¼Œipå¯ä»¥æ—¶IPã€åŸŸåã€åˆ«å æŸ¥è¯¢ç”¨æˆ·å 1whoami SSHå…¬å…±é’¥ç™»å½• 12ssh -p 22 user@ipssh user@ip -p port ç›´æ¥è·³è½¬åˆ°é‡ç‚¹â€”â€”å…å¯†ç™»å½•ï¼Œè¿™ä¸ªæ˜¯æˆ‘ä»¬æ­å»ºé›†ç¾¤éœ€è¦åšçš„ä¸€ä¸ªå…³é”®æ­¥éª¤ï¼Œå¯ä»¥æå¤§çš„æ–¹ä¾¿æˆ‘ä»¬è¿›è¡ŒèŠ‚ç‚¹çš„åˆ‡æ¢ã€æ‹·è´ã€éƒ¨ç½²ï¼Œæ‰€ä»¥å¿…é¡»è¦æŒæ¡ï¼Œä¹Ÿæ¨èä½¿ç”¨ã€‚ ç”ŸæˆSSHå¯†é’¥ 1ssh-keygen å¯†é’¥ç”Ÿæˆåï¼Œå­˜å‚¨ä½ç½®ä¸ºï¼š ~&#x2F;.ssh&#x2F;id_rsa.pub\tå…¬é’¥å­˜å‚¨åœ°å€ ~&#x2F;.ssh&#x2F;id_rsa ç§é’¥å­˜å‚¨åœ°å€ å¤åˆ¶å¯†é’¥åˆ°åˆ†èŠ‚ç‚¹ä¸­ 12ssh-copy-id masterssh-copy-id user@ip -p port Macå®‰è£…ssh-copy-id 1brew install ssh-copy-id æ­¤æ¡ç”¨äºæ²¡æœ‰å®‰è£…ssh-copy-idå‘½ä»¤æ—¶ï¼Œä½¿ç”¨çš„å®‰è£…å‘½ä»¤ï¼Œä»…é™äºMacï¼ˆé¢ï¼Œå’Œè¿™ä¸ªæ­å»ºæ²¡ä»€ä¹ˆå…³ç³»ï¼Œå°±æ˜¯ä¸€ä¸ªè¡¥å……çš„è¯´æ˜ï¼‰ Windowsæ‰‹åŠ¨æŒ‡ä»¤ 1ssh user@ip -p port â€˜mkdir -p .ssh&amp;&amp; cat &gt;&gt; .ssh/authorized_keysâ€™ &lt; ~/.ssh/id_rsa.pub æˆ–è€…æ‰‹åŠ¨æ“ä½œï¼Œå¤åˆ¶å…¬é’¥å†…å®¹ï¼Œç„¶åç™»å…¥è¿œç¨‹æœºå™¨ï¼Œç²˜è´´åˆ° ~&#x2F;.ssh&#x2F;id_rsa.pub å…¬é’¥å­˜å‚¨åœ°å€ .ssh&#x2F;authorized_keyså­˜å‚¨å…¶ä»–å…¬é’¥çš„ä½ç½® SSHé…ç½®åˆ«å 12345vi ~/.ssh/configHost labHostName remoteUser userPort port ä¸ªäººç›®å‰æ²¡æœ‰ä½¿ç”¨è¿‡ï¼Œä½†æ˜¯åœ¨sshå…¶ä»–æœåŠ¡å½“ä¸­æœ‰ä»‹ç»sshåˆ«åçš„ä½¿ç”¨æ–¹æ³•ï¼Œéœ€è¦çš„è¯ä¹Ÿå¯ä»¥è®°ä¸€ä¸‹ã€‚ å®Œæˆäº†å…å¯†ç™»å½•ï¼Œæ¥ä¸‹æ¥ä»‹ç»ä¸€ä¸‹SSHä¼ è¾“æ–‡ä»¶æœåŠ¡ï¼Œä½¿ç”¨æ­¤å‘½ä»¤å¯ä»¥æå¤§çš„æé«˜æ–‡ä»¶åœ¨é›†ç¾¤å†…ä¼ è¾“çš„æ•ˆç‡â€”â€”å‰ææ˜¯éœ€è¦åšå¥½ä¸Šé¢çš„æ­¥éª¤ã€‚ ä¼ è¾“æ–‡ä»¶å¤¹ 1scp -r /path/file-titele/file user@ip:/path/file-titele ä½¿ç”¨åˆ«å 1scp port /path/to/local/file lab:/path/to/local/file å°†è¿œç¨‹æ–‡ä»¶ä¸‹è½½åˆ°æœ¬åœ° 1scp lab:port /path/to/local/file /path/to/local/file å°†æœ¬åœ°æ–‡ä»¶ä¼ è¾“åˆ°è¿œç¨‹ 1scp -P port /path/to/local/file user@ipï¼š/path/to/local/file å…¶ä¸­ï¼Œportä¸ºç«¯å£å·ï¼Œpathä¸ºè·¯å¾„ï¼Œfileä¸ºæ–‡ä»¶åï¼Œä¼ è¾“æ—¶å¦‚æœä¼ è¾“åŒä¸€åœ°å€ï¼Œåœ¨è¢«ä¼ è¾“çš„æ–‡ä»¶å¤¹ä¸‹ï¼Œä¼ è¾“è·¯å¾„æ˜¯ä¼ è¾“è€…çš„ä¸Šä¸€çº§æ–‡ä»¶ï¼ˆå› ä¸ºæ–‡ä»¶è¿˜æ²¡ä¼ è¿‡å»hhh,è¿™å¥è¯å°±æ˜¯åºŸè¯ï¼‰ ä»¥ä¸Šä½¿ç”¨çš„æ–¹æ³•éƒ½å¤§å·®ä¸å·®ï¼Œä¸»è¦çš„åŒºåˆ«å°±æ˜¯ä¿®æ”¹äº†å‚æ•°è¾¾æˆä¸åŒçš„æ•ˆæœï¼Œå¦‚æœè¦è¯¦ç»†äº†è§£å„å‚æ•°çš„å«ä¹‰ï¼Œå¯ä»¥æœç´¢ä»¥ä¸‹ï¼Œè¿™é‡Œæˆ‘å°±åªè´´å¼ å›¾ï¼Œä¸åšå…¶ä»–è¯´æ˜ï¼Œéœ€è¦çš„è‡ªå–å°±å¥½å•¦ã€‚ ä¼ è¾“æ–‡ä»¶ JDKå› ä¸ºHadoopçš„ç”Ÿæ€ç¯å¢ƒï¼Œéƒ½æ˜¯ä»¥Javaä¸ºåº•å±‚é€»è¾‘ç¼–å†™çš„ï¼Œæ‰€ä»¥åœ¨é…ç½®ç¯å¢ƒå‰ï¼Œéœ€è¦åšçš„ä¸€ä¸ªå¿…è¦é…ç½®ï¼Œå°±æ˜¯é…ç½®JDKã€‚è¿™æ˜¯é…ç½®Hadoopçš„å‰ç½®è¦æ±‚ï¼Œä¹Ÿæ˜¯Hadoopé›†ç¾¤ç”Ÿæ€åœˆçš„åº•å±‚é€»è¾‘ã€‚ è§£å‹æ–‡ä»¶åˆ°æŒ‡å®šç›®å½• 1tar -zxvf /opt/software/jdk.tar.gz -C /opt/module/ ä¿®æ”¹ç¯å¢ƒå˜é‡ 123vi /etc/profileexport JAVA_HOME=/opt/module/jdkexport PATH=$PATH:$JAVA_HOME/bin ç»“è¯­","categories":["Linux"]},{"title":"Kafkaæ­å»º","path":"/2024/04/25/kafka-build/","content":"Kafkaå®‰è£…é…ç½®Zookeeperå®‰è£…é…ç½®åœ¨é…ç½®Kafkaä¹‹å‰ï¼Œéœ€è¦å®‰è£…zookeeper è§£å‹æ–‡ä»¶ 1tar -zxvf /opt/software/zookeeper.tar.gz -C /opt/module/ @é…ç½®ç¯å¢ƒå˜é‡1234vi /etc/profileexport ZOOKEEPER_HOME=/opt/module/apache-zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/binsource /etc/profile @é…ç½®æ–‡ä»¶#myid123cd /opt/module/apache-zookeepermkdir dataecho 1 &gt; data/myid #zoo.cfg1234567cd /opt/module/apche-zookeeper/confcp zoo_sample.cfg zoo.cfgvi /opt/module/apache-zookeeper/zoo.cfgdataDir=/opt/module/apache-zookeeper/dataserver.1=master:2888:3888server.2=slave1:2888:3888server.3=slave2:2888:3888 @å¯åŠ¨é›†ç¾¤123cd /opt/module/apache-zookeeper/binzkServer.sh startzkServer.sh status æŸ¥è¯¢çŠ¶æ€ 1zkServer.sh status å¯åŠ¨å®ŒæˆåjpsæŸ¥è¯¢ èŠ‚ç‚¹åç§° è¿›ç¨‹çŠ¶æ€ master Modeï¼šfollower slave1 Modeï¼šleader slave2 Modeï¼šfollower zookeeperæ­£å¸¸å¯åŠ¨åè¿›ç¨‹çŠ¶æ€å¦‚ä¸Šè¡¨æ‰€ç¤ºï¼Œæ³¨æ„ï¼šjpsæŸ¥è¯¢ä¸ä¼šæœ‰ç»“æœ Kafkaå®‰è£…é…ç½®å½“zookeeperé…ç½®å®Œæˆåï¼Œå³å¯å¼€å§‹é…ç½®kafka @é…ç½®ç¯å¢ƒå˜é‡123vi /etc/profileexport KAFKA_HOME=/opt/module/kafkaexport PATH=$PATH:$KAFKA_HOME/bin @é…ç½®æ–‡ä»¶åœ¨é…ç½®æ–‡ä»¶æ—¶ï¼Œæœ‰ä¸¤ä¸ªæ€è·¯ï¼Œä¸€ä¸ª æ˜¯å¯ç”¨kafkaè‡ªå¸¦çš„zookeeperï¼Œå¦ä¸€ä¸ªæ˜¯å¯åŠ¨zookeeperåå•ç‹¬å¯åŠ¨kafkaã€‚åœ¨è¿™é‡Œæˆ‘ä½¿ç”¨çš„æ˜¯ç¬¬äºŒç§æ–¹æ³•ï¼Œç¬¬ä¸€ç§æ–¹æ³•çš„é…ç½®å†…å®¹åœ¨æ–‡æœ«å†è¿›è¡Œè¯´æ˜ã€‚ #server.properties1234broker.id=1listeners=PLAINTEXT://192.168.100.3:9092log.dirs=/opt/module/kafka/kafka-logszookeeper.connect=master:2181,slave1:2181,slave2:2181 broker.idä¸ºè‡ªå®šä¹‰çš„æ•°å­—ï¼Œå¯ä»¥è‡ªå·±è®¾å®šï¼Œä½†æ˜¯éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œkafkaé›†ç¾¤ä¸­æ¯å°èŠ‚ç‚¹çš„idå€¼ä¸å¯ä»¥ç›¸ç­‰ã€‚ listenersä¸ºç›‘å¬åœ°å€ï¼Œé…ç½®ä¸»èŠ‚ç‚¹çš„ipåœ°å€å³å¯ã€‚ log.dirsä¸ºkafkaçš„æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œè·¯å¾„è‡ªå®šä¹‰å³å¯ï¼Œæ—¥å¿—æ–‡ä»¶å¤¹ä¼šè‡ªåŠ¨åˆ›å»ºã€‚ zookeeper.connecté…ç½®ä¸ºä¸‰å°èŠ‚ç‚¹çš„zookeeperç«¯å£å’Œipåç§°å³å¯ã€‚ å¦‚æœä¸é€‚ç”¨è‡ªå¸¦çš„zookeeperï¼Œä¸Šè¿°å‘½ä»¤å³å¯å®Œæˆkafkaæ­å»ºã€‚ ä¸‹é¢çš„å†…å®¹æ˜¯ä½¿ç”¨è‡ªå¸¦çš„zookeeperéœ€è¦é…ç½®çš„ã€‚ #data&#x2F;zkè¿™é‡Œçš„é…ç½®æ–¹æ³•å’Œzookeeperä¸­çš„ç›¸åŒï¼Œä¹Ÿæ˜¯åœ¨æ ¹ç›®å½•ä¸‹æ–°å»ºæ–‡ä»¶å¤¹ï¼Œç„¶ååœ¨æ–‡ä»¶å¤¹ä¸­å†™å…¥myidï¼Œæ³¨æ„å„èŠ‚ç‚¹çš„myidå€¼éœ€è¦å¯¹åº”serveråé¢çš„å€¼ã€‚åŒæ—¶ï¼Œåé¢dataDirå¯¹åº”çš„è·¯å¾„åä¹Ÿæ˜¯myidå¯¹åº”çš„è·¯å¾„åã€‚ #zookeeper.properties123456789vi /opt/module/kafka/config/zookeeper.propertiestickTime=2000initLimit=10syncLimit=5clientPort=2181dataDir=/opt/moduele/kafka/data/zkserver.1=192.168.100.3:2888:3888server.2=192.168.100.4:2888:3888server.3=192.168.100.2:2888:3888 æ­¤æ–‡ä»¶çš„é…ç½®å†…å®¹å’Œzookeeperä¸­zoo.cfgå†…å®¹ç›¸åŒï¼Œå”¯ä¸€éœ€è¦æ³¨æ„çš„æ˜¯zoo.cfgçš„æ¨¡æ¿æ–‡ä»¶ä¼šæ·»åŠ å¥½å‰å‡ æ¡å†…å®¹ä½œä¸ºé»˜è®¤é…ç½®ï¼Œä½†æ˜¯zookeeper.propertiesä¸­éœ€è¦è‡ªå·±æ‰‹åŠ¨æ·»åŠ ã€‚ @å¯åŠ¨é›†ç¾¤æ‹·è´é›†ç¾¤ 12345scp -r /opt/module/kafka slave1:/opt/module/scp -r /opt/module/kafka slave1:/opt/module/scp -r /etc/profile slave1:/etc/scp -r /etc/profile slave2:etc/source /etc/profile æ›´æ”¹é…ç½® è®°å¾—åœ¨ä»èŠ‚ç‚¹ä¸Šæ›´æ”¹broker.idå’Œlistenersç›‘å¬ç«¯å£çš„ipåœ°å€ï¼ˆè™½ç„¶æˆ‘ä¹‹å‰å¥½è¡Œå¿˜è®°æ”¹ipåœ°å€ä¹Ÿæ­£å¸¸å¯åŠ¨äº†ï¼Œä½†æ˜¯ä¸çŸ¥é“ä¸é…ç½®ä¼šä¸ä¼šæœ‰ä»€ä¹ˆå½±å“ï¼Œè¿˜æ˜¯é…ä¸Šå§å“ˆå“ˆã€‚ï¼‰ å¯åŠ¨Zookeeperï¼ˆå†…ç½®ï¼‰ 1./bin/zookeeper-server-start.sh config/zookeeper.properties &amp; å¯åŠ¨Kafka 1./bin/kafka-server.start.sh config/server.properties &amp; åœæ­¢zk&#x2F;kafka 12./kafka-server-stop.sh./zookeeper-server.stop.sh å†å¼€å…¶å®è¦å…ˆå¼€å¯zkå†å¼€å¯kafkaï¼ŒåŒç†å…³é—­çš„æ—¶å€™ä¹Ÿåº”è¯¥å…ˆå…³é—­kafkaå†å…³é—­zkï¼ˆåº”è¯¥ç”¨ä¸ç€ï¼‰ @JPSå¯åŠ¨å®Œæˆåï¼Œéœ€è¦è¿›è¡ŒæŸ¥è¯¢çŠ¶æ€è¿›ç¨‹æ¥ç¡®è®¤æ˜¯å¦æˆåŠŸå¯åŠ¨äº†zkå’Œkafka 1jps èŠ‚ç‚¹åç§° è¿›ç¨‹çŠ¶æ€ master QuorumPeerMainã€kafka slave1 QuorumPeerMainã€kafka slave2 QuorumPeerMainã€kafka QuorumPeerMainè¿›ç¨‹ä¸ºzookeeperæˆåŠŸå¯åŠ¨åçš„è¿›ç¨‹ kafkaä¸ºkafkaæˆåŠŸå¯åŠ¨åçš„è¿›ç¨‹ éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼Œå¦‚æœåˆ›å»ºkafka-topicä¸­replication-facorï¼ˆå‰¯æœ¬æ•°ï¼‰å¤§äº1çš„è¯ï¼Œéœ€è¦å¯åŠ¨åˆ†èŠ‚ç‚¹çš„kafkaè¿›ç¨‹ï¼Œå¦‚æœä¸å¯åŠ¨åˆ†èŠ‚ç‚¹çš„kafkaï¼Œåˆ™æ— æ³•åˆ›å»ºï¼Œä¼šæŠ¥é”™brokerå€¼å°äºå‰¯æœ¬æ•°ã€‚ Kafka-shellç®€å•çš„åˆ›å»ºtopic kafka-topicåˆ›å»ºæ–¹æ³•æœ‰ä¸¤ä¸ª éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼Œå¦‚æœåˆ›å»ºkafka-topicä¸­replication-facorï¼ˆå‰¯æœ¬æ•°ï¼‰å¤§äº1çš„è¯ï¼Œéœ€è¦å¯åŠ¨åˆ†èŠ‚ç‚¹çš„kafkaè¿›ç¨‹ï¼Œå¦‚æœä¸å¯åŠ¨åˆ†èŠ‚ç‚¹çš„kafkaï¼Œåˆ™æ— æ³•åˆ›å»ºï¼Œä¼šæŠ¥é”™brokerå€¼å°äºå‰¯æœ¬æ•°ã€‚ bootstrap1./bin/kafka-topics.sh --bootstrap-server localhost:9092(,loclalhost1:9092,localhost2:9092) --list â€“list\tæŸ¥è¯¢é›†ç¾¤ä¸­æ˜¯å¦æœ‰topic â€“bootstrap-server localhost:9092\tè¿æ¥æœåŠ¡å™¨ï¼Œlocalhostä¸ºæœ¬é›†ç¾¤åç§°ï¼Œ9092ä¸ºç«¯å£å·ï¼Œæµ‹è¯•ç¯å¢ƒä¸‹å†™ä¸€ä¸ªå³å¯ï¼Œç”Ÿäº§ç¯å¢ƒåˆ™2-3ä¸ª 1./bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic name --create --partitions 1 --replication-factor 3 â€“topic name é€‰ä¸­topicï¼Œnameä¸ºtopicåå­—ï¼Œnameå¯è‡ªå®šä¹‰æ›´æ”¹ â€“create åˆ›å»ºtopic â€“partitions 1 è®¾ç½®åˆ†åŒºï¼Œ1å¯ä»¥æ”¹ä¸ºè‡ªå®šä¹‰åˆ†åŒº â€“replication-factor 3 è®¾ç½®å‰¯æœ¬æ•°ï¼Œ3å¯ä»¥æ”¹ä¸ºè‡ªå®šä¹‰å‰¯æœ¬æ•° 1./bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic name --describe -topic name\té€‰ä¸­topicï¼Œnameä¸ºtopicåå­—ï¼Œnameå¯è‡ªå®šä¹‰æ›´æ”¹ â€“describe\tæŸ¥è¯¢name topicçš„è¯¦ç»†ä¿¡æ¯ zookeeper1bin/kafka-topics.sh --zookeeper localhost:2181 --topic name --create --partitions 1 --replication-factor 3 ä¸¤ä¸ªæ–¹æ³•ä¸ä¸€æ ·çš„åœ°æ–¹æ˜¯å†topicåé¢ä½¿ç”¨çš„æŒ‡ä»¤ï¼Œæˆ‘ç°åœ¨ä½¿ç”¨çš„æ˜¯--zookeeperï¼Œæ²¡æœ‰ä½¿ç”¨--bootstrap-serverçš„åŸå› æ˜¯åè€…åˆ›å»ºtopicæˆåŠŸæ²¡æœ‰æç¤ºï¼ˆâ€¦â€¦ä½†æ˜¯æˆ‘å°±æ˜¯è¦é‚£ä¸ªæç¤ºï¼‰ bootstrapå’Œzookeeperçš„åŒºåˆ«æˆ‘ä»¬ä½¿ç”¨çš„kafkaç‰ˆæœ¬ä¸º2.xç‰ˆæœ¬ï¼Œè€Œ**#â€“bootstrap-server**ä¸ºkafka3.xç‰ˆæœ¬çš„æŒ‡ä»¤ Kafkaå¼€å‘å›¢é˜Ÿé‡å†™äº†ZooKeeperçš„Quorumæ§åˆ¶å™¨ä»£ç å¹¶åµŒå…¥åˆ°Kafkaä¸­ã€‚æ‰€ä»¥ä»v2.8ç‰ˆæœ¬å¼€å§‹ï¼ŒKafkaä¸å†ä¾èµ–ZooKeeperã€‚ æ‰€ä»¥ï¼Œ æ—§ç‰ˆï¼š 1--zookeeper localhost:2181 æ–°ç‰ˆï¼š 1--bootstrap-server localhost:9092 å…¶ä¸­ï¼Œ2181æ˜¯ZooKeeperçš„ç›‘å¬ç«¯å£ï¼Œ9092æ˜¯Kafkaçš„ç›‘å¬ç«¯å£ã€‚ æ—§ç‰ˆç”¨â€“zookeeperå‚æ•°ï¼Œä¸»æœºåï¼ˆæˆ–IPï¼‰å’Œç«¯å£ç”¨ZooKeeperçš„ï¼Œä¹Ÿå°±æ˜¯server.propertiesæ–‡ä»¶ä¸­zookeeper.connectå±æ€§çš„é…ç½®å€¼ æ–°ç‰ˆç”¨â€“bootstrap-serverå‚æ•°ï¼Œä¸»æœºåï¼ˆæˆ–IPï¼‰å’Œç«¯å£ç”¨æŸä¸ªèŠ‚ç‚¹çš„å³å¯ï¼Œå³ä¸»æœºåï¼ˆæˆ–ä¸»æœºIPï¼‰:9092ã€‚ é™„è¡¨ï¼ˆéœ€è¦çš„è‡ªå–ï¼‰ï¼š kafka shell order explain ä½œç”¨ â€“alter Alter the number of partitions,replication assignment,and&#x2F;or configuration for the topic. æ”¹ â€“bootstrap-server&lt;String: server to connect to&gt; REQUIRED:The Kafka server to connect to. è¿æ¥ â€“topic&lt;String: topic&gt; The topic to create, alter,describe or delete.It also accepts a regular expresstion,except for â€“create option.Put topic name in double quotes and use the â€˜ \\ â€˜ prefix to escape regular expression symbols; e.g.â€test \\ .topicâ€. topic â€“create Create a new topic. å¢ â€“delete Delete a topic åˆ  â€“list List all available topics æŸ¥ â€“describe List details for the given topics æŸ¥ â€“partitions&lt;Integer: # of partitions&gt; The number of partitions for the topic being created or altered(WARNING:If partitions are increased for a topic that has a key,the partition logic or ordering).If not supplied for create,defalts to the cluster default. åˆ†åŒº â€“repliction-factor&lt;Integer:replication factor&gt; The replication factor for each partition in the topic being created.If not supplied,defaults to the cluster default. å‰¯æœ¬","categories":["Kafka"]},{"title":"Hiveæ­å»º","path":"/2024/04/25/hive-build/","content":"Hiveé…ç½®MySQLé…ç½®mysqlçš„é…ç½®æ¯”è¾ƒå¤æ‚å’Œéº»çƒ¦ï¼Œå»ºè®®å•ç‹¬é…ç½®å¥½äº†å†è¿›è¡Œä¸‹ä¸€æ­¥ï¼ˆè™šæ‹Ÿæœºé…ç½®mysqlæˆåŠŸåè®°å¾—å¤šæ‹·è´å‡ ä»½ï¼ï¼ï¼ï¼‰ Hiveé…ç½®è§£å‹æ–‡ä»¶ 1tar -zxvf /opt/software/apache-hive -C /opt/module @é…ç½®ç¯å¢ƒ1234vi /etc/profileexport HIVE_HOME=/opt/module/apache-hiveexport PATH=$PATH:$HIVE_HOME/binsource /etc/profile @é…ç½®æ–‡ä»¶#hive-site.xml12345678910111213141516171819vi /opt/module/apache-hive/conf/hive-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://localhost/hive?createDatabaseIfNotExist=true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;root&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;123456&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hive-site.xmlé…ç½®æ–‡ä»¶å¯ä»¥ç”±hive-default.xml.tamplateæ¨¡æ¿æ–‡ä»¶å¤åˆ¶è€Œæ¥ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ä½¿ç”¨ viæ¥è¿›è¡Œä¹¦å†™åˆ›å»ºã€‚åŸºç¡€çš„hiveé…ç½®åªéœ€è¦å®Œæˆä¸Šè¿°å››æ¡çš„é…ç½®å³å¯ã€‚ ConnectionURLï¼Œmysqlæ•°æ®åº“çš„è®¿é—®è·¯å¾„ï¼Œæ²¡æœ‰è·¯å¾„åˆ™æ€»åŠ¨åˆ›å»ºï¼› ConnectionDriverNameï¼Œè¿æ¥mysqlæ•°æ®åº“çš„é©±åŠ¨ï¼› ConnectionUserNameï¼Œè¿æ¥mysqlæ•°æ®åº“çš„ç”¨æˆ·åï¼› ConnectionPasswordï¼Œè¿æ¥mysqlæ•°æ®åº“çš„ç§˜å¯†ã€‚ #hive-env.sh12345vi /opt/module/apache-hive/conf/hive-env.shexport JAVA_HOME=$&#123;JAVA_HOME&#125;export HIVE_HOME=$&#123;HIVE_HOME&#125;export HADOOP_HOME=$&#123;HADOOP_HOME&#125;export HIVE_CONF_DIR=$&#123;HIVE_HOME&#125;/conf è¿™é‡Œéœ€è¦é…ç½® jdkã€hadoopã€hiveã€hive/confå››æ¡è·¯å¾„ä¿¡æ¯ @æ¶åŒ…#mysql-connect.jar.gz1cp /opt/software/mysql-connection.jar.gz /opt/module/apache-hive/lib mysqlçš„è¿æ¥æ¶åŒ…ï¼Œåœ¨è€ç‰ˆæœ¬ä¸­ï¼Œç»™å‡ºçš„mysqlæ¶åŒ…æ˜¯ä¸€ä¸ªå‹ç¼©åŒ…ï¼Œå…¶ä¸­æœ‰ä¸¤ä¸ªæ¶åŒ…éœ€è¦ç§»åŠ¨ï¼› è€Œåœ¨æ–°ç‰ˆæœ¬ä¸­ï¼Œåªéœ€è¦ç§»åŠ¨è¿™ä¸€ä¸ªæ¶åŒ…å³å¯ã€‚ #guava.jar1cp /opt/module/hadoop/share/hadoop/common/lib/guava2.7.jar /opt/module/apache-hive/lib guava.jaræ˜¯hadoop3.1.3æ–°ç‰ˆæœ¬ä¸­çš„é—®é¢˜ï¼Œæ˜¯apacheé¡¹ç›®ä¸­å¯¹åº”çš„ç‰ˆæœ¬æ— æ³•å’Œhadoopç‰ˆæœ¬å¯¹åº”å¯¼è‡´çš„é—®é¢˜ï¼Œæ‰€ä»¥å½“å‰ç‰ˆæœ¬æŠ¥é”™ï¼Œéœ€è¦æŠŠhadoopä¸‹çš„2.xç‰ˆæœ¬çš„æ¶åŒ…ç§»åŠ¨åˆ°å¯¹åº”é¡¹ç›®çš„libæ–‡ä»¶å¤¹ä¸‹ï¼Œå¹¶ä¸”åˆ é™¤ä»¥å‰çš„æ—§ç‰ˆæœ¬ï¼Œå³å¯å®Œæˆã€‚ åˆ é™¤guava1.x.jar 1rm -rf /opt/module/apache-hive/lib/guava.1.x.jar åˆ é™¤è€ç‰ˆæœ¬æ¶åŒ…å†è¿è¡Œã€‚ @åˆå§‹åŒ–ä¸å¯åŠ¨#åˆå§‹åŒ–1schematool -dbType mysql -initSchema è¿™ä¸ªç‰ˆæœ¬çš„hiveåˆå§‹åŒ–æ—¶ï¼Œä¼šå‡ºç°å¤§ç‰‡ç©ºç™½ï¼Œç»è¿‡å’¨è¯¢ï¼Œæ˜¯æ­£å¸¸æƒ…å†µã€‚ 1schematool -dbType mysql -initSchema --verbose è¡¥å……ï¼Œä½¿ç”¨ä»¥ä¸ŠæŒ‡ä»¤æ—¶å€™ï¼Œå³åŠ ä¸Š--verboseåˆ™æ­£å¸¸æ˜¾ç¤ºï¼Œä¸ä¼šå‡ºç°ç©ºç™½bugã€‚ #å¯åŠ¨1hive --service metaservice &amp;","categories":["Hive"]},{"title":"Hbaseæ­å»º","path":"/2024/04/25/hbase-build/","content":"Hbaseè§£å‹æ–‡ä»¶ 1tar -zxvf /opt/software/hbase -C /opt/module/ é…ç½®ç¯å¢ƒ12345vi /etc/profileexport HBASE_HOME=/opt/module/hbaseexport PATH=$PATH:$HBASE_HOME/binepxort HADOOP_CLASSPATH=$&#123;HADOOP_HOME&#125;/lib/*source /etc/profile ç¬¬ä¸‰æ¡å¥½åƒä¸éœ€è¦è¿›è¡Œé…ç½®ï¼Œå®æµ‹ä¸‹æ¥ä¸é…ç¬¬ä¸‰æ¡ä¹Ÿèƒ½æ­£å¸¸è¿è¡Œ é…ç½®æ–‡ä»¶@hbase-env.sh123vi /opt/module/hbase/hbase-env.shexport JAVA_HOME=/opt/module/jdkexport HBASE_MANAGES_ZK=false HBASE_MANAGES_ZKå«ä¹‰æ˜¯ä¸ä½¿ç”¨hbaseè‡ªå¸¦çš„zookeeper @hbase-site.xml12345678910111213141516171819202122232425vi /opt/module/hbase/hbase-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/opt/module/hbase/data&lt;/value&gt; &lt;/property&gt; //ä¸é…ç½®æ­¤æ¡å‘½ä»¤ä¼šå¯¼è‡´HMasterè¿›ç¨‹æ— æ³•å¯åŠ¨ &lt;property&gt; &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; hbase.rootdirä¸­çš„valueå€¼éœ€è¦å’Œhadoopä¸­core-site.xmlä¸­é…ç½®çš„ç«¯å£å·ç›¸åŒï¼Œåé¢çš„hbaseå¯ä»¥è‡ªå®šä¹‰ï¼› hbase.zookeeper.property.dataDirè®°å½•çš„æ˜¯å­˜å‚¨æ—¥å¿—æ–‡ä»¶çš„è·¯å¾„ï¼› hbase.unsafe.steam.capability.enforceï¼Œæ³¨æ„è¿™æ¡å‘½ä»¤ï¼Œç»è¿‡å¤šæ¬¡æµ‹è¯•ï¼Œæ­¤ç‰ˆæœ¬çš„hbaseå¦‚æœä¸é…ç½®æ­¤æ¡æŒ‡ä»¤ï¼Œä¼šå¯¼è‡´hbaseå¯åŠ¨åï¼ŒHMasterè‡ªåŠ¨banæ‰ï¼Œè¿›å…¥hbase-shellåè¾“å…¥æŒ‡ä»¤æŠ¥é”™ï¼ï¼ï¼ hbase.zookeeper.quorumä¸­å¯ä»¥åªå†™masterã€slave1ã€slave2ä¸‰ä¸ªå€¼ï¼Œä½†æ˜¯å¦‚æœè¿™ä¹ˆå†™çš„è¯ï¼Œéœ€è¦å†åŠ ä¸€æ¡protæ¥è®°å½•zookeeperçš„ç«¯å£å·ã€‚ 1234&lt;property&gt; &lt;name&gt;hbase.zookeeper.prot&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt;&lt;/property&gt; @regionservers1234vi /opt/module/hbase/conf/regionserversmasterslave1slave2 regionserversä¸­ä¸‰å°èŠ‚ç‚¹éƒ½éœ€è¦å†™å…¥ï¼Œregionserversç”¨äºå¯åŠ¨HRegionServerè¿›ç¨‹ï¼Œæ‰€ä»¥ï¼Œä¸å¯ä»¥åªå†™åˆ†èŠ‚ç‚¹ã€‚å¦‚æœåªå†™åˆ†èŠ‚ç‚¹ï¼Œä¼šå¯¼è‡´æ— æ³•æ­£å¸¸å¯åŠ¨HRegionServerè¿›ç¨‹ã€‚ åˆ†å‘èŠ‚ç‚¹ä¸å¯åŠ¨é›†ç¾¤@åˆ†å‘èŠ‚ç‚¹12345scp -r /opt/module/hbase slave1:/opt/modulescp -r /opt/module/hbase slave2:/opt/modulescp -r /etc/profile slave1:/etc/profilescp -r /etc/profile slave2:/etc/profilesource /etc/profile @å¯åŠ¨é›†ç¾¤1start-hbase.sh åœ¨ä¸»èŠ‚ç‚¹å¯åŠ¨å³å¯ã€‚ Hbase Shellè¿›å…¥hbase 1hbase shell æŸ¥çœ‹å‘½åç©ºé—´ 1list_namespace éƒ¨åˆ†æŠ¥é”™ HAç»„ä»¶ä¸‹ HAç»„ä»¶ä¸‹ï¼ŒHbase-2.2.3ç‰ˆæœ¬çš„å¯åŠ¨ä¼šå‡ºç°HRegionServerè¿›ç¨‹æ— æ³•å¯åŠ¨ï¼Œæ ¹æ®æŠ¥é”™æ¨æ–­æ˜¯æœ‰å…³namenodeçš„é€»è¾‘åæœ‰å…³çš„æŠ¥é”™ è§£å†³æ–¹æ³•ï¼š 12cp /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml /opt/module/hbase-2.2.3/confcp /opt/module/hadoop-3.1.3/etc/hadoop/hdfs-site.xml /opt/module/hbase-2.2.3/conf å°†Hadoopä¸­core-siteå’Œhdfs-siteæ–‡ä»¶copyåˆ°hbaseçš„confæ–‡ä»¶å¤¹ä¸‹ï¼Œåœ¨è¿›è¡Œå¯åŠ¨å³å¯æ­£å¸¸å¯åŠ¨ã€‚","categories":["Hbase"]},{"title":"Hadoopæ­å»º","path":"/2024/04/25/hadoop-build/","content":"Hadoopæ­å»ºå†™åœ¨æœ€å‰ï¼Œæœ¬æ–‡ä¸­æ‰€ä½¿ç”¨çš„é…ç½®æ˜¯å¯ä»¥è¾¾åˆ°ä½¿ç”¨hadoopé›†ç¾¤æ­å»ºçš„æœ€åŸºæœ¬é…ç½®ï¼Œå¦‚æœæœ‰å…¶ä»–éœ€æ±‚ï¼ŒæŒ‰ç…§è‡ªå·±çš„éœ€æ±‚å»å¢åŠ æˆ–åˆ é™¤é…ç½®æ–‡ä»¶å³å¯ï¼Œæœ¬æ–‡åªé˜è¿°æœ€åŸºæœ¬ç”¨ä¾‹ï¼ŒåæœŸä¼˜åŒ–å°±é è‡ªå·±å•¦~åŠ æ²¹å™¢ğŸ’ª Hadoopå®Œå…¨åˆ†å¸ƒå¼å®‰è£…è§£å‹åˆ°æŒ‡å®šæ–‡ä»¶å¤¹ 1tar -zxvf /opt/software/hadoop.tar.gz -C /opt/module/ æ¯ä¸€ä¸ªæ–‡ä»¶çš„é…ç½®æ— å¤–ä¹å°±ä¸¤ä¸ªé…ç½®å†…å®¹ï¼Œä¸€ä¸ªæ˜¯ç¯å¢ƒå˜é‡çš„é…ç½®ï¼Œä¸€ä¸ªæ˜¯æ–‡ä»¶å†…çš„é…ç½®ã€‚è€Œè¦ä½¿ç”¨çš„ç¬¬ä¸€æ­¥ï¼Œè‡ªç„¶å°±æ˜¯å®‰è£…ã€‚æˆ‘ä»¬é‡‡ç”¨çš„å®‰è£…æ–¹æ³•æ˜¯å‹ç¼©åŒ…å®‰è£…ï¼Œæ‰€ä»¥æˆ‘ä»¬å®‰è£…çš„ç¬¬ä¸€æ­¥ï¼Œæ˜¯è§£å‹æ–‡ä»¶ @é…ç½®ç¯å¢ƒå˜é‡123vi /etc/profileexport HADOOP_HOME=/opt/module/hadoopexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin ä»¥ä¸Šæ˜¯hadoop2.7ç‰ˆæœ¬ä¸­ç¯å¢ƒå˜é‡éœ€è¦é…ç½®çš„å†…å®¹ã€‚ åœ¨è¿™é‡Œå†æä¸€ä¸ªLinux shellè¯­æ³•ï¼Œå¯ä»¥å¿«é€ŸæŸ¥è¯¢è·¯å¾„ï¼š æŸ¥è¯¢å½“å‰æ‰€åœ¨è·¯å¾„å 1pwd ä½†æ˜¯åœ¨hadoopçš„3.1.3çš„ç‰ˆæœ¬ä¸­ï¼Œéœ€è¦åŠ å…¥ä»¥ä¸‹å†…å®¹ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚å¹¸è¿çš„æ˜¯ï¼ŒæŠ¥é”™å†…å®¹ä¹Ÿä¼šæç¤ºä½ å¦‚ä½•å»ä¿®æ”¹ç¯å¢ƒå˜é‡ã€‚ï¼ˆè¿™æ˜¯ç¬¬ä¸€ç§é…ç½®æ–¹å¼ï¼Œæ–‡ç« ç»“å°¾çš„è¡¥å……è¯´æ˜ä¸­ï¼Œæˆ‘ä¼šè®²è¿°ç¬¬äºŒç§é…ç½®æ–¹å¼ğŸ¤£å½“ç„¶æˆ‘è¿˜æ˜¯è§‰å¾—è¿™ç§é…ç½®èµ·æ¥æ›´æ–¹ä¾¿å•¦ï¼‰ 12345export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root hadoop3.1.3ç‰ˆæœ¬éœ€è¦åŠ å…¥ä»¥ä¸Šå†…å®¹ã€‚ å…¨å±€ç¯å¢ƒå˜é‡ç”Ÿæ•ˆ 1source /etc/profile æ¯æ¬¡ä¿®æ”¹å®Œç¯å¢ƒå˜é‡éœ€è¦å¯¹ç¯å¢ƒå˜é‡è¿›è¡Œç”Ÿæ•ˆå‘½ä»¤ã€‚ å…³äºç¯å¢ƒå˜é‡çš„ç”Ÿæ•ˆï¼Œå†è¡¥å……ä¸€äº›å†…å®¹ã€‚ å¦‚æœå½“å‡ºç°å…¨å±€å˜é‡é…ç½®å‡ºç°é—®é¢˜å¯¼è‡´åŸºç¡€å‘½ä»¤å¤±æ•ˆçš„æƒ…å†µâ€”â€” æœ‰ä¸€ä¸ªæœ€é«˜ä½çš„å‘½ä»¤å¯ä»¥ä½¿ç”¨ï¼š å…¨å±€å˜é‡ä¿®æ”¹ 1/bin/vi /etc/profile å…¨å±€å˜é‡ç”Ÿæ•ˆ 1./etc/profile ä»¥ä¸Šæ–¹æ³•æ— æ³•è§£å†³ç›´æ¥è¾“å…¥ 1export PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin æˆ–è€… ä½¿ç”¨æœ€é«˜ä½æŒ‡ä»¤è¿›å…¥&#x2F;etc&#x2F;profileåè¾“å…¥ 1export PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin @é…ç½®æ–‡ä»¶é…ç½®æ–‡ä»¶æ¨¡æ¿ 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;&lt;/name&gt; &lt;value&gt;&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; æ²¡å•¥ç”¨ï¼Œå­˜ä¸€ä¸ªï¼Œæ–¹ä¾¿å¤åˆ¶ç²˜è´´ã€‚ #core-site.xml1234567891011vi /opt/module/hadoop/etc/hadoop/core-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; NameNodeå†…éƒ¨é€šä¿¡çš„ç«¯å£åœ¨hadoop3.1.3ç‰ˆæœ¬ä¸­æœ‰ä¸‰ä¸ªå¸¸ç”¨ç«¯å£å·ï¼š8020ï¼Œ9000ï¼Œ9820ï¼Œæˆ‘å¸¸ç”¨çš„ç«¯å£å·æ˜¯9000ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒClickhouseçš„é»˜è®¤ç«¯å£å·ä¹Ÿæ˜¯9000ï¼Œæ‰€ä»¥å½“éœ€è¦é…ç½®ä¸¤ä¸ªçš„æ—¶å€™ï¼Œæœ‰ä¸€ä¸ªéœ€è¦æ›´æ”¹ç«¯å£å·ï¼Œå¦åˆ™ä¼šå‡ºç°å ç”¨çš„æƒ…å†µã€‚ hadoop.tmp.dirå­˜å‚¨çš„æ˜¯hadoopæ–‡ä»¶ç³»ç»Ÿä¾èµ–ï¼Œå®ƒæœ‰é»˜è®¤ä½ç½®åœ¨æ ¹ç›®å½•çš„&#x2F;tmpä¸‹ï¼Œä½†æ˜¯å­˜å‚¨äºé»˜è®¤ä½ç½®ä¸‹çš„tmpæ–‡ä»¶æ˜¯ä¸´æ—¶æ–‡ä»¶ï¼Œåœ¨æœºå™¨è¿›è¡Œå¼€å…³æ—¶ä¼šé‡ç½®ä¸¢å¤±æ–‡ä»¶ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ‰‹åŠ¨ä¸ºå®ƒé…ç½®ä¸€ä¸ªè·¯å¾„ã€‚æˆ‘å†™çš„dataæ–‡ä»¶å¤¹æ˜¯å®‰è£…åŒ…ä¸è‡ªå¸¦çš„ï¼Œdataæ–‡ä»¶åœ¨æ‰§è¡ŒNameNodeçš„åˆå§‹åŒ–æ—¶ä¼šè‡ªåŠ¨ç”Ÿæˆï¼Œä¹Ÿå¯ä»¥è‡ªå·±ä¸ºå®ƒåˆ›å»ºã€‚ æ–°å»ºdataæ–‡ä»¶å¤¹ 1mkdir data #hdfs-site.xml1234567891011vi /opt/module/hadoop/etc/hadoop/hdfs-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address&lt;/name&gt; &lt;value&gt;master:9870&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;slave1:9868&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; dfs.namenode.http-addressæ˜¯dfs namenode web uiä½¿ç”¨çš„ç›‘å¬åœ°å€å’ŒåŸºæœ¬ç«¯å£ï¼Œæˆ‘è¿™é‡Œè®¾ç½®çš„åŸºæœ¬ç«¯å£å·ä¸º9870ã€‚ dfs.namenode.secondary,http-addressåŒç†æ˜¯SecondaryNameNodeä½¿ç”¨çš„ç›‘å¬åœ°å€å’ŒåŸºæœ¬ç«¯å£ï¼Œæˆ‘è¿™é‡Œè®¾ç½®çš„åŸºæœ¬ç«¯å£å·ä¸º9868ã€‚ #yarn-site.xml1234567891011vi /opt/module/hadoop/etc/hadoop/yarn-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;slave2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; yarn.reosurcemanager.hostnameï¼Œå¦‚åå­—æ‰€ç¤ºï¼Œå°±æ˜¯ç”¨äºæŒ‡å®šresourcemanagerçš„ä¸»æœºåã€‚ yarn.nodemanager.aux-serviceså±æ€§ç”¨äºæŒ‡å®šåœ¨è¿›è¡Œmapreduceä½œä¸šæ—¶ï¼Œyarnä½¿ç”¨mapreduce_shuffleæ··æ´—æŠ€æœ¯ã€‚shuffleæ˜¯MapReduceä¸­é‡è¦çš„ç»„æˆéƒ¨åˆ†ï¼Œå·¥ä½œåŸç†è¿™é‡Œå°±ä¸è¿›è¡Œèµ˜è¿°äº†ã€‚ å…·ä½“çš„å·¥ä½œåŸç†æˆ‘æ”¾åˆ°å…¶ä»–æ–‡ç« é‡Œè¿›è¡Œè®²è¿°ï¼Œè¿™é‡Œæˆ‘ä»¬å…ˆè®²é…ç½®ã€‚ #mapred-site.xml1234567vi /opt/module/hadoop/etc/hadoop/mapred-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapreduce.framework.nameå±æ€§ç”¨äºæ‰§è¡ŒMapReduceä½œä¸šçš„è¿è¡Œæ—¶æ¡†æ¶ã€‚å±æ€§å€¼å¯ä»¥æ˜¯localï¼Œclassicï¼Œyarnã€‚ä»€ä¹ˆæƒ…å†µä¸‹ä½¿ç”¨ä»€ä¹ˆå±æ€§å€¼ï¼Œæˆ‘ä»¬åœ¨å…¶ä»–æ–‡ç« é‡Œå†è¿›è¡Œè®²è¿°ã€‚ åœ¨hadoop2.7ç‰ˆæœ¬ä¸­ï¼Œmapred-site.xmlæ˜¯ä¸€ä¸ªæ¨¡æ¿æ–‡ä»¶ï¼Œæ–‡ä»¶åä¸ºï¼šmapred-site.xml.templateï¼Œå¦‚æœè¦è¿›è¡Œé…ç½®ï¼Œå°±å¤åˆ¶æ¨¡æ¿æ–‡ä»¶ï¼Œåœ¨å¤åˆ¶çš„æ–°æ–‡ä»¶ä¸­è¿›è¡Œé…ç½®ã€‚ å¤åˆ¶æ¨¡æ¿æ–‡ä»¶ 1cp mapred-site.xml.template mapred-site.xml æ„ä¸ºï¼Œå¤åˆ¶æ¨¡æ¿æ–‡ä»¶ï¼Œå‘½åä¸ºï¼šmapred-site.xml #hadoop-env.sh12vi /opt/module/hadoop/etc/hadoop/hadoop-env.shexport JAVA_HOME=/opt/module/jdk å…³äºhadoo-env.shï¼Œåœ¨hadoop2.7çš„ç‰ˆæœ¬ä¸­ï¼Œæˆ‘ä¼šé…ç½®ä¸‰ä¸ª.shæ–‡ä»¶ï¼ˆhadoop-env.shã€yarn-env.shã€mapred-env..shï¼‰çš„jdkè·¯å¾„ï¼Œä½†æ˜¯å…·ä½“ç”¨å¤„ä¸å¤ªäº†è§£ï¼ˆç­‰æˆ‘æŸ¥ä¸€æŸ¥å†è¯´ï¼‰ï¼Œåœ¨hadoop3.1.3çš„ç‰ˆæœ¬ä¸­ï¼Œæˆ‘å°è¯•è¿‡ä¸é…ç½®jdkè·¯å¾„ï¼Œå‘ç°ä¼šæŠ¥é”™ï¼Œäºæ˜¯é…ç½®äº†hadoop-env.shè¿™ä¸ªæ–‡ä»¶çš„jdkè·¯å¾„ï¼Œè§£å†³é—®é¢˜ã€‚æ‰€ä»¥ç»“è®ºæ˜¯éœ€è¦é…ç½®è¿™ä¸ªæ–‡ä»¶ï¼Œè¿™ä¸ªæ–‡ä»¶çš„å…·ä½“å«ä¹‰ç­‰æˆ‘æŸ¥äº†å†è¿›è¡Œè¡¥å……ã€‚ #wokers1234vi /opt/module/hadoop/etc/hadoop/workersmasterslave1slave2 wokersæ–‡ä»¶çš„åŸèº«æ˜¯æ—§ç‰ˆæœ¬ä¸­çš„slavesï¼Œåœ¨hadoop2.7ç‰ˆæœ¬ä¸­ï¼Œæ­¤æ–‡ä»¶åä¸ºslavesï¼Œåœ¨hadoop3.1.3ç‰ˆæœ¬ä¸­ï¼Œæ­¤æ–‡ä»¶åä¸ºwokersï¼Œè™½ç„¶æ›´æ”¹çš„åå­—ï¼Œä½†æ˜¯æ–‡ä»¶çš„é…ç½®å†…å®¹ä¸å‘ç”Ÿæ”¹å˜ã€‚ @å¯åŠ¨é›†ç¾¤#æ‹·è´æ–‡ä»¶1234scp -r /opt/module/hadoop/ slave1:/opt/modulescp -r /opt/module/hadoop/ slave2:/opt/modulescp -r /etc/profile slave1:/etc/scp -r /etc/profile slave2:/etc/ å°†hadoopã€ç¯å¢ƒå˜é‡æ‹·è´åˆ°ä¸¤å¤–ä¸¤ä¸ªèŠ‚ç‚¹ï¼ŒåŒæ—¶æ³¨æ„å¦å¤–ä¸¤ä¸ªèŠ‚ç‚¹è¦è¿›è¡Œç¯å¢ƒå˜é‡çš„ç”Ÿæ•ˆã€‚ #åˆå§‹åŒ–NameNode123cd /opt/module/hadoop/binhdfs namenode -formathadoop namenode -format ä¸¤ç§å‘½ä»¤éƒ½å¯ä»¥è¿›è¡ŒNameNodeçš„åˆå§‹åŒ–ï¼Œä¸è¿‡éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæ ¹æ®ç‰ˆæœ¬ä¸åŒï¼Œæœ‰ä¸€äº›å‘½ä»¤å¯èƒ½ä¼šå‡ºç°è¢«æ·˜æ±°çš„æƒ…å†µï¼Œä¸è¿‡ç›®å‰æ¥è¯´ï¼Œå¹¶æœªç¦ç”¨ï¼Œä»ç„¶å¯ä»¥ç»§ç»­ä½¿ç”¨ï¼Œæ‰€ä»¥æ— ä¼¤å¤§é›…ğŸ¤£ é…ä¸€å¼ æ ¼å¼åŒ–æˆåŠŸçš„å›¾ç‰‡ å‡ºç°æ ‡çº¢å­—ä½“å³ä»£è¡¨åˆå§‹åŒ–æˆåŠŸ éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œå¦‚æœæ›´æ”¹äº†æ ¹ç›®å½•ä¸‹çš„ä¸€äº›æ–‡ä»¶ï¼Œåˆ™éœ€è¦é‡æ–°åˆå§‹åŒ–NameNodeï¼Œä»¥ä¿è¯NamNodeçš„é…ç½®ï¼Œå¦‚pidæ–‡ä»¶ä¸ä¼šå‡ºç°é—®é¢˜ï¼Œå¦åˆ™ï¼Œé›†ç¾¤å¯èƒ½æ— æ³•å¯åŠ¨ï¼Œæ— æ³•ä½¿ç”¨ã€‚ #å¯åŠ¨é›†ç¾¤1234cd /opt/module/hadoop/sbinstart-dfs.shstart-yarn.shstart-all.sh éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œå¯åŠ¨ä¸åŒé›†ç¾¤éœ€è¦åœ¨é…ç½®çš„é‚£å°æœºå™¨ä¸Šè¿›è¡Œå¯åŠ¨ï¼Œæ¯”å¦‚æˆ‘çš„ResourceManageré…ç½®åœ¨äº†slave2èŠ‚ç‚¹ä¸Šï¼Œé‚£ä¹ˆæˆ‘å°±è¦è¿›å…¥åˆ°slave2ä¸­hadoopçš„sbinæ–‡ä»¶å¤¹ä¸‹å¯åŠ¨start-yarn.shï¼Œæ‰èƒ½æ­£å¸¸å¯åŠ¨ResourceManagerä»¥åŠNodeManagerã€‚ å…¶ä¸­ä¸‰æ¡å‘½ä»¤ï¼Œè¦ä¹ˆé€‰æ‹©start-dfs.shåŠ start-yarn.shï¼Œè¦ä¹ˆé€‰æ‹©start-all.shï¼ŒäºŒé€‰å…¶ä¸€å³å¯ã€‚ å¯åŠ¨å®Œæˆåï¼Œå¯ä»¥é€šè¿‡jpsæ¥æŸ¥è¯¢å„èŠ‚ç‚¹è¿›ç¨‹ï¼Œæ­£ç¡®çš„è¿›ç¨‹çŠ¶æ€å¦‚ä¸‹è¡¨ èŠ‚ç‚¹å æ‹¥æœ‰è¿›ç¨‹ master NameNodeã€DataNodeã€Jpsã€NodeManager slave1 SecondaryNameNodeã€DataNodeã€Jpsã€NodeManager slave2 ResourceManagerã€DataNodeã€Jpsã€NodeManager è¿›ç¨‹æ‰€åœ¨èŠ‚ç‚¹æ ¹æ®ä¸åŒçš„é›†ç¾¤è§„åˆ’ä¼šåœ¨ä¸åŒçš„åœ°æ–¹ï¼Œä½†æ˜¯ä»¥ä¸Šè¿›ç¨‹å¿…é¡»æ‹¥æœ‰ï¼Œå¦‚æœæ²¡æœ‰å¯¹åº”è¿›ç¨‹ï¼Œåˆ™è¯æ˜å¯åŠ¨å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ã€æŠ¥é”™ä¿¡æ¯è¿›è¡Œé…ç½®æ–‡ä»¶çš„ä¿®æ”¹ã€‚ Hadoopä¼ªåˆ†å¸ƒå¼å®‰è£…æœ‰å…³Hadoopçš„ä¼ªåˆ†å¸ƒå¼é…ç½®ï¼Œå°±ç®€å•çš„æä¸€å˜´ï¼ŒHadoopçš„ä¼ªåˆ†å¸ƒå¼æ˜¯åœ¨åªæœ‰ä¸€å°æœºå™¨æ—¶ï¼Œæ¨¡æ‹Ÿçš„é›†ç¾¤é…ç½®ï¼Œæ‰€ä»¥å’Œå®Œå…¨åˆ†å¸ƒå¼é…ç½®ä¸åŒçš„åœ°æ–¹åœ¨äºï¼Œå› ä¸ºåªæœ‰ä¸€å°æœºå™¨ï¼Œæ‰€ä»¥æ‰€æœ‰å†…å®¹å¿…é¡»æ­å»ºåœ¨åŒä¸€å°æœºå™¨ï¼Œå³æ‰€æœ‰èŠ‚ç‚¹ç«¯å£ï¼Œéƒ½é…ç½®åœ¨masterèŠ‚ç‚¹ä¸Šï¼ˆçœ‹ä½ ä»…å­˜çš„èŠ‚ç‚¹åå«ä»€ä¹ˆhhhğŸ¤£ï¼‰å³å¯ã€‚ Hadoop on Yarn(HA)å†™åœ¨æœ€å‰ï¼šå…³äºHadoopHAçš„å†…å®¹ï¼Œä¸ªäººç†è§£ä¸æ·±ï¼Œç›®å‰åªèƒ½è¾¾åˆ°èƒ½åšé¢˜ç›®çš„æ°´å¹³ï¼Œå¯¹é…ç½®é¡¹å†…çš„å‚æ•°ä¹Ÿå¹¶ä¸æ˜¯ååˆ†ç†è§£ã€‚æ­¤å¤–ï¼Œè¿˜éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå…³äºHadoopHAçš„åç»­å®‰è£…ï¼Œç›®å‰å®æµ‹åªæˆåŠŸäº†kafkaã€hiveï¼Œå¤±è´¥æŠ¥é”™flumeçš„æ•°æ®é‡‡é›†éƒ¨åˆ†ï¼ˆä»æœªè§£å†³ï¼‰ğŸ˜­ğŸ˜­ã€‚ Hadoop çš„HAæœ‰ä¸¤ä¸ªå‰ç½®ç¯å¢ƒéœ€è¦å®‰è£…ï¼Œç¬¬ä¸€ä¸ªæ˜¯JAVAç¯å¢ƒï¼Œç¬¬äºŒä¸ªæ˜¯Zookeeperç¯å¢ƒã€‚ JAVAç¯å¢ƒåœ¨ç¬¬ä¸€ç« ä¸­æˆ‘ä»¬å·²ç»è¿›è¡Œè¿‡äº†é…ç½®ï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æ¥é…ç½®iæ‰€éœ€è¦çš„ç¬¬äºŒç§ç¯å¢ƒâ€”â€” Zookeeperé…ç½®è§£å‹æ–‡ä»¶ 1tar -zxvf /opt/software/zookeeper.tar.gz -C /opt/module/ è§£å‹å‹ç¼©åŒ…åˆ°æŒ‡å®šæ–‡ä»¶å¤¹ä¸­ã€‚ @é…ç½®ç¯å¢ƒå˜é‡1234vi /etc/profileexport ZOOKEEPER_HOME=/opt/module/apache-zookeeperexport PATH=$PATH:$ZOOKEEPER_HOME/binsource /etc/profile @é…ç½®æ–‡ä»¶#myid123cd /opt/module/apache-zookeepermkdir dataecho 1 &gt; data/myid å¯¹äºzookeeperï¼Œé¦–å…ˆæ˜¯æ¯ä¸ªèŠ‚ç‚¹çš„myidå€¼ï¼Œè¿™ä¸ªmyidå€¼å†è¿›è¡Œæ–‡ä»¶æ‹·è´åï¼Œéœ€è¦åœ¨ä¸åŒçš„èŠ‚ç‚¹å†™ä¸Šä¸åŒçš„å€¼ï¼Œå€¼å¿…é¡»å’Œzoo.cfgæ–‡ä»¶ä¸­server.xä¸­xçš„å€¼ç›¸åŒï¼Œæ³¨æ„å¯¹åº”èŠ‚ç‚¹ã€‚æˆ‘çš„é…ç½®ä¸‹ï¼ŒmasterèŠ‚ç‚¹ä¸º1ï¼Œslave1èŠ‚ç‚¹ä¸º2ï¼Œslave2èŠ‚ç‚¹ä¸º3ã€‚ #zoo.cfg1234567cd /opt/module/apche-zookeeper/confcp zoo_sample.cfg zoo.cfgvi /opt/module/apache-zookeeper/zoo.cfgdataDir=/opt/module/apache-zookeeper/dataserver.1=master:2888:3888server.2=slave1:2888:3888server.3=slave2:2888:3888 é¦–å…ˆè¿›å…¥åˆ°zookeeperçš„confæ–‡ä»¶å¤¹ä¸‹ï¼Œconfæ–‡ä»¶å¤¹ä¸‹æœ‰ä¸€ä¸ªzoo_sample.cfgæ–‡ä»¶ï¼Œæˆ‘ä»¬éœ€è¦å¯¹è¿™ä¸ªè¿›è¡Œä¿®æ”¹ï¼Œä½†æ˜¯åŒæ ·çš„ï¼Œè¿™ä¸ªæ–‡ä»¶ä¹Ÿåªæ˜¯ä¸€ä¸ªæ¨¡æ¿æ–‡ä»¶ï¼Œæ‰€ä»¥åœ¨è¿›è¡Œä¿®æ”¹é…ç½®ä¹‹å‰ï¼Œæˆ‘ä»¬è¦å…ˆæ‹·è´æ­¤æ–‡ä»¶ã€‚ zoo.cfgæ–‡ä»¶çš„ä¿®æ”¹å†…å®¹ä¸ºä¸¤å¤„â€”â€” dataDirï¼Œè¿™æ¡å±æ€§å­˜å‚¨çš„æ˜¯zookeeperå„ä¸ªèŠ‚ç‚¹çš„myidå€¼ï¼Œè·¯å¾„è®¾ç½®ä¸ºzookeeperæ ¹ç›®å½•ä¸‹çš„dataæ–‡ä»¶å¤¹ï¼Œä¹Ÿå°±æ˜¯æŒ‡å‘myidå€¼å³å¯ server.x&#x3D;ip:2888:3888ï¼Œè¿™æ¡å±æ€§å°±æ˜¯å¯¹åº”myidçš„å€¼ï¼Œxå³ä½ åœ¨å½“å‰èŠ‚ç‚¹ä¸‹myidæ‰€éœ€è¦é…ç½®çš„å€¼ï¼Œipå¯ä»¥æ˜¯IPåä¹Ÿå¯ä»¥æ˜¯IPåœ°å€ï¼Œå…·ä½“æ˜¯ä»€ä¹ˆï¼Œå¯ä»¥å…·ä½“æƒ…å†µéƒ½è¯•è¯•çœ‹ï¼ˆğŸ¤£ï¼‰ï¼Œå› ä¸ºæ›¾ç»å‡ºç°è¿‡IPåæŠ¥é”™ï¼Œä½†æ˜¯IPåœ°å€å¯ä»¥ä½¿ç”¨çš„æƒ…å†µï¼Œä½†æ˜¯hhhç½‘ä¸Šçš„éƒ½è¯´ä¸å¯ä»¥ç”¨IPåœ°å€ï¼Œå””ï¼Œå…·ä½“åŸå› è¿˜æ²¡æœ‰ç ”ç©¶è¿‡ï¼Œç­‰åé¢å†ç ”ç©¶äº†çœ‹ã€‚ @å¯åŠ¨é›†ç¾¤123cd /opt/module/apache-zookeeper/binzkServer.sh startzkServer.sh status zookeeperçš„å¯åŠ¨æ˜¯æœ‰è¯´æ³•çš„ï¼Œè¿™ä¸ªåŸç†å…³ç³»åˆ°zookeeperçš„é€‰ä¸¾æœºåˆ¶ã€‚è¿™é‡Œå°±å…ˆä¸è¿›è¡Œèµ˜è¿°äº†ã€‚ä¸»è¦åˆ†ä¸ºä¸¤ä¸ªè¿›ç¨‹â€”â€”Modeï¼šfollowerå’ŒModeï¼šLeaderã€‚ åŒæ—¶è¿˜æœ‰ä¸€ä¸ªéœ€è¦æ³¨æ„çš„åœ°æ–¹ï¼Œzookeeperçš„å¯åŠ¨éœ€è¦ä¸‰å°åŒæ—¶å¯åŠ¨ï¼Œè¿™ä¸ªå¯ä»¥å€ŸåŠ©Xshellå·¥å…·æˆ–è€…æ˜¯è‡ªä¸»ç¼–å†™è„šæœ¬ï¼Œæˆ–è€…å¦ä¸€ç§æ–¹å¼æ˜¯å•èŠ‚ç‚¹çš„ä¸€å°ä¸€å°å¯åŠ¨ã€‚å…¶ä¸­å¯åŠ¨å®è·µåº”è¯¥æ˜¯æ§åˆ¶åœ¨30000msä»¥å†…ï¼ˆè¿˜æ²¡æ‰¾åˆ°å…·ä½“çš„æ—¶é—´è¦æ±‚ï¼Œä½†æ˜¯å¾ˆä¹…ä»¥å‰å¥½åƒåœ¨å“ªé‡Œçœ‹åˆ°è¿‡ï¼‰ã€‚æ ¹æ®zookeeperçš„é€‰ä¸¾æœºåˆ¶ï¼Œç¬¬ä¸€å°å’Œç¬¬ä¸‰å°å¯åŠ¨çš„èŠ‚ç‚¹ä¸ºfollowèŠ‚ç‚¹ï¼Œç¬¬äºŒå°å¯åŠ¨çš„èŠ‚ç‚¹ä¸ºleaderèŠ‚ç‚¹ã€‚ å¯ä»¥é€šè¿‡ æŸ¥è¯¢çŠ¶æ€ 1zkServer.sh status å¯åŠ¨å®ŒæˆåjpsæŸ¥è¯¢ èŠ‚ç‚¹åç§° è¿›ç¨‹çŠ¶æ€ master Modeï¼šfollower slave1 Modeï¼šleader slave2 Modeï¼šfollower zookeeperæ­£å¸¸å¯åŠ¨åè¿›ç¨‹çŠ¶æ€å¦‚ä¸Šè¡¨æ‰€ç¤ºï¼Œæ³¨æ„ï¼šjpsæŸ¥è¯¢ä¸ä¼šæœ‰ç»“æœ HadoopHAéƒ¨ç½²è§£å‹æ–‡ä»¶ 1tar -zxvf /opt/software/hadoop-3.1.3 -C /opt/module/ @é…ç½®ç¯å¢ƒå˜é‡è¿™é‡Œé…ç½®çš„ç‰ˆæœ¬æ˜¯hadoop-3.1.3ï¼Œæ‰€ä»¥ç¯å¢ƒå˜é‡ä¸­å¤šå‡ºæ¥çš„ä¸ƒé¡¹ï¼Œåœ¨hadoop-2.7ç‰ˆæœ¬ä¸­ä¸éœ€è¦é…ç½® 123456789101112vi /etc/profileexport HADOOP_HOME=/opt/module/hadoop-3.1.3export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/bin//ä»¥ä¸‹æ˜¯hadoop-3.1.3ç‰ˆæœ¬ä¸­éœ€è¦é¢å¤–é…ç½®çš„ï¼Œè¿™äº›é…ç½®å†…å®¹è¿˜å¯ä»¥é…ç½®åœ¨å¯åŠ¨æ–‡ä»¶æˆ–è€…æ˜¯hadoop-env.shä¸­export HDFS_NAMENODE_USER=rootexport HDFS_DATANODE_USER=rootexport HDFS_SECONDARYNAMENODE_USER=rootexport YARN_RESOURCEMANAGER_USER=rootexport YARN_NODEMANAGER_USER=root//ä»¥ä¸‹æ˜¯hadoop-3.1.3ç‰ˆæœ¬ä¸­HAæ‰€éœ€è¦çš„æ–°é…ç½®å†…å®¹export HDFS_ZKFC_USER=rootexport HDFS_JOURNALNODE_USER=root ä»¥ä¸Šå†…å®¹åœ¨å¯åŠ¨æ—¶ï¼Œå¦‚æœæ²¡æœ‰é…ç½®æˆ–æ˜¯é…ç½®æœ‰è¯¯ï¼Œä¼šerroræŠ¥é”™æç¤ºï¼Œä½†æ˜¯ï¼Œè¿™é‡Œæ¨èé…ç½®å¥½ï¼Œä¸è¦åˆ°æ—¶å€™å†è¿›è¡Œä¿®æ”¹ï¼Œå¯èƒ½ä¼šå‡ºç°è§£å†³ä¸äº†æŠ¥é”™é—®é¢˜ã€‚ @é…ç½®æ–‡ä»¶#hadoop-env.sh12vi /opt/module/hadoop-3.1.3/etc/hadoop/hadoop-env.shexport JAVA_HOME=/opt/module/jdk #core-site.xml12345678910111213141516171819202122232425262728293031323334vi /opt/module/hadoop-3.1.3/etc/hadoop/&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://mycluster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-3.1.3/dfs/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt; &lt;/property&gt; &lt;!-- ğŸ‘‡âŒ --&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131072&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.proxyuser.root.users&lt;/name&gt; &lt;value&gt;*&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; fs.defaultFSï¼šHadoop FS å®¢æˆ·ç«¯ä½¿ç”¨çš„é»˜è®¤è·¯å¾„ hadoop.tmp.dirï¼šHadoopä¸´æ—¶æ–‡ä»¶è·¯å¾„ ha.zookeeper.quorumï¼šé…ç½®zké›†ç¾¤ dfs.journalnode.edits.dirï¼šJournalNodeå®ˆæŠ¤è¿›ç¨‹å°†å­˜å‚¨å…¶æœ¬åœ°çŠ¶æ€çš„è·¯å¾„ io.file.buffer.sizeï¼šSequenceFilesä¸­ä½¿ç”¨çš„è¯»&#x2F;å†™ç¼“å†²åŒºçš„å¤§å° hadoop.proxyuser.root.hostsï¼šé…ç½®å…è®¸è®¿é—®çš„ä¸»æœº hadoop.proxyuser.root.groupsï¼šé…ç½®å…è®¸è®¿é—®çš„ç”¨æˆ·ç»„ hadoop.proxyuser.root.usersï¼šé…ç½®è¿è¡Œè®¿é—®çš„ç”¨æˆ· #hdfs-site.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172vi /opt/module/hadoop-3.1.3/etc/hadoop/hdfs-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;mycluster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;master:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;slave1:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt; &lt;value&gt;master:9870&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt; &lt;value&gt;slave1:9870&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://master:8485;slave1:8485;slave2:8485/mycluster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-3.1.3/data/jn&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.mycluter&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence shell(/bin/bash) &lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/root/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;!-- ğŸ‘‡âŒ --&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.connection-timeout&lt;/name&gt; &lt;value&gt;30000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/opt/module/hadoop-3.1.3/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.blocksize&lt;/name&gt; &lt;value&gt;268435456&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;100&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; dfs.nameservicesï¼šnameservicesé€»è¾‘åç§° dfs.ha.namenodes.myclusterï¼šnameservicesæœåŠ¡ä¸­æ¯ä¸ªNameNodeçš„å”¯ä¸€æ ‡è¯†ç¬¦ dfs.ha.namenode.rpc-address.mycluster.nnXï¼šnnX NameNodeç›‘å¬çš„å®Œå…¨é™å®šçš„RPCåœ°å€ dfs.ha.namenode.http-address.mycluster.nnXï¼šnnX NameNodeç›‘å¬çš„å®Œå…¨é™å®šçš„HTTPåœ°å€ dfs.namenode.shared.edits.dirï¼šæ ‡è¯†NameNode å°†åœ¨å…¶ä¸­å†™å…¥&#x2F;è¯»å–ç¼–è¾‘çš„ JN ç»„çš„URL dfs.client.failover.proxy.provider.myclusterï¼šHDFSå®¢æˆ·ç«¯ç”¨æ¥è”ç³»Active NameNodeçš„Javaç±» dfs.ha.fencing.methodsï¼šä¸€ä¸ªè„šæœ¬æˆ–JAVAç±»çš„åˆ—è¡¨ï¼Œå°†åœ¨æ•…éšœè½¬ç§»æœŸé—´ç”¨äºéš”ç¦»Active NameNode dfs.ha.fencing.ssh.private-key-filesï¼šSSH åˆ° Active NameNode å¹¶ç»ˆæ­¢è¿›ç¨‹ dfs.ha.fencing.ssh.connect-timeoutï¼šSSHè¿æ¥è¶…æ—¶æ—¶é•¿(æ¯«ç§’) dfs.ha.automatic-failover.enabledï¼šå¼€å¯è‡ªåŠ¨æ•…éšœè½¬ç§» dfs.replicationï¼šHadoopçš„å‰¯æœ¬æ•°é‡ï¼Œé»˜è®¤ä¸º3 dfs.namenode.name.dirï¼šåœ¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿæ‰€åœ¨çš„NameNodeçš„å­˜å‚¨ç©ºé—´å’ŒæŒç»­åŒ–å¤„ç†æ—¥å¿— dfs.datanode.data.dirï¼šåœ¨æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿæ‰€åœ¨çš„DataNodeçš„å­˜å‚¨ç©ºé—´å’ŒæŒç»­åŒ–å¤„ç†æ—¥å¿— dfs.blocksizeï¼šç”¨äºå¤§å‹æ–‡ä»¶ç³»ç»Ÿçš„ HDFS å—å¤§å°ä¸º 256MB dfs.namenode.handler.countï¼šNameNode æœåŠ¡å™¨çº¿ç¨‹æ¥å¤„ç†æ¥è‡ªå¤§é‡DataNode çš„ RPC #yarn-site.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566vi /opt/module/hadoop-3.1.3/etc/hadoop/yarn-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;RMcluster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;slave1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.zk.address&lt;/name&gt; &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt; &lt;/property&gt; &lt;!-- ğŸ‘‡âŒ --&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt; &lt;value&gt;1024&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt; &lt;value&gt;4096&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt; &lt;value&gt;5&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt; &lt;value&gt;master:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt; &lt;value&gt;slave1:8088&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; yarn.scheduler.minimum-allocation-mbï¼šåœ¨èµ„æºç®¡ç†å™¨ä¸­åˆ†é…ç»™æ¯ä¸ªå®¹å™¨è¯·æ±‚çš„æœ€å°å†…å­˜é™åˆ¶ã€‚ä»¥ MB ä¸ºå•ä½ yarn.scheduler.maximum-allocation-mbï¼šåœ¨èµ„æºç®¡ç†å™¨ä¸­åˆ†é…ç»™æ¯ä¸ªå®¹å™¨è¯·æ±‚çš„æœ€å¤§å†…å­˜é™åˆ¶ã€‚ä»¥ MB ä¸ºå•ä½ yarn.nodemanager.resource.cpu-vcoresï¼šå¯ä»¥ä¸ºå®¹å™¨åˆ†é…çš„ vcore æ•°é‡ï¼Œè¿™ä¸ç”¨äºé™åˆ¶ YARN å®¹å™¨ä½¿ç”¨çš„ç‰©ç†å†…æ ¸æ•°ã€‚é»˜è®¤ä¸º8 yarn.resourcemanager.ha.enabledï¼šå¯ç”¨ RM HA yarn.resourcemanager.cluster-idï¼šæ ‡è¯†é›†ç¾¤ã€‚é€‰ä¸¾äººä½¿ç”¨å®ƒæ¥ç¡®ä¿ RM ä¸ä¼šæ¥ç®¡å¦ä¸€ä¸ªé›†ç¾¤çš„æ´»åŠ¨ yarn.resourcemanager.ha.rm-idsï¼šRM çš„é€»è¾‘ ID åˆ—è¡¨ yarn.resourcemanager.hostname.rmXï¼šæŒ‡å®š RMé€»è¾‘id,rmXå¯¹åº”çš„ä¸»æœºå yarn.resourcemanager.webapp.address.rmXï¼šæŒ‡å®š RMé€»è¾‘id,rmXå¯¹åº”çš„webåœ°å€ hadoop.zk.addressï¼šæŒ‡å®šhadoopé›†ç¾¤ #mapred-site.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354vi /opt/module/hadoop-3.1.3/etc/hadoop/mapred-site.xml&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;!-- ğŸ‘‡âŒ --&gt; &lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.reduce.env&lt;/name&gt; &lt;value&gt;HADOOP_MAPRED_HOME=/opt/module/hadoop-3.1.3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt; &lt;value&gt;2048&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.java.opts&lt;/name&gt; &lt;value&gt;-Xmx1536M&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt; &lt;value&gt;4096&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.java.opts&lt;/name&gt; &lt;value&gt;-Xmx2560M&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;master:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:19888&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/name&gt; &lt;value&gt;/mr-history/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt; &lt;value&gt;/mr-history/done&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; mapreduce.framework.nameï¼šæ‰§è¡Œæ¡†æ¶è®¾ç½®ä¸º Hadoop YARN mapreduce.map.memory.mbï¼šmapreduce.map.memory.mb mapreduce.map.java.optsï¼šmapä»»åŠ¡å­jvmçš„å †å¤§å° mapreduce.reduce.memory.mbï¼šreduceä»»åŠ¡çš„èµ„æºé™åˆ¶ mapreduce.map.java.optsï¼šreduceä»»åŠ¡å­jvmçš„å †å¤§å° mapreduce.jobhistory.addressï¼šMapReduce JobHistory æœåŠ¡å™¨ä¸»æœºï¼šç«¯å£ mapreduce.jobhistory.webapp.addressï¼šMapReduce JobHistory Server Web UIä¸»æœºï¼šç«¯å£ mapreduce.jobhistory.intermediate-done-dirï¼šMapReduce ä½œä¸šå†™å…¥å†å²æ–‡ä»¶çš„ç›®å½• mapreduce.jobhistory.done-dirï¼šå†å²æ–‡ä»¶ç”± MR JobHistory Server ç®¡ç†çš„ç›®å½• #workers1234vi /opt/module/hadoop-3.1.3/etc/hadoop/workersmasterslave1slave2 @å¯åŠ¨é›†ç¾¤ åˆ†å‘èŠ‚ç‚¹ å¯åŠ¨JournalNodeï¼ˆ3å°èŠ‚ç‚¹ï¼‰ 1hdfs --daemon start journalnode æ ¼å¼åŒ–namenode 1hdfs namenode -format æ ¼å¼åŒ–zkfc 1hdfs zkfc -formatZK å¯åŠ¨é›†ç¾¤ 1start-all.sh å¤‡ç”¨NameNodeå¤åˆ¶å…ƒæ•°æ®ç›®å½•ï¼ˆ2å°åˆ†èŠ‚ç‚¹ï¼‰ 12hdfs namenode -bootstrapStandbyhdfs --daemon start namenode æŸ¥çœ‹æ‰€æœ‰NameNodeçŠ¶æ€ 1hdfs haadmin -getAllServiceState è¿è¡ŒPiç¨‹åºæµ‹è¯• 1yarn jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar pi 10 10 é‡å¯master namenode 12hdfs --daemon start namenodehdfs haadmin -getServiceState nn1","categories":["Hadoop"]},{"title":"Flumeæ­å»º","path":"/2024/04/25/flume-build/","content":"Flumeé…ç½®è§£å‹æ–‡ä»¶ 1tar -zxvf /opt/software/apache-flume -C /opt/module/ @é…ç½®ç¯å¢ƒ123vi /etc/profileexport FLUME_HOME=/opt/module/apache-flumeexport PATH=$PATH:$FLUME_HOME/bin @é…ç½®æ–‡ä»¶#flume-env.sh12vi /opt/module/flume/conf/flume-env.shexport JAVA_HOME=/opt/module/jdk flume-env.shæ˜¯temlateæ¨¡æ¿æ–‡ä»¶ï¼Œéœ€è¦è‡ªå·±è¿›è¡Œå¤åˆ¶ #log4j.properties123vi /opt/module/flume/conf/log4j.propertiesflume.log.dir=/opt/module/flume/logsflume.log.file=flume.log @æ¶åŒ…#guava.jar1cp /opt/module/hadoop/share/hadoop/common/lib/guava2.7.jar /opt/module/apache-flume/lib å’Œhiveä¸€æ ·ï¼Œguava.jaræ˜¯hadoop3.1.3æ–°ç‰ˆæœ¬ä¸­çš„é—®é¢˜ï¼Œæ˜¯apacheé¡¹ç›®ä¸­å¯¹åº”çš„ç‰ˆæœ¬æ— æ³•å’Œhadoopç‰ˆæœ¬å¯¹åº”å¯¼è‡´çš„é—®é¢˜ï¼Œæ‰€ä»¥å½“å‰ç‰ˆæœ¬æŠ¥é”™ï¼Œéœ€è¦æŠŠhadoopä¸‹çš„2.xç‰ˆæœ¬çš„æ¶åŒ…ç§»åŠ¨åˆ°å¯¹åº”é¡¹ç›®çš„libæ–‡ä»¶å¤¹ä¸‹ï¼Œå¹¶ä¸”åˆ é™¤ä»¥å‰çš„æ—§ç‰ˆæœ¬ï¼Œå³å¯å®Œæˆã€‚ åˆ é™¤guava1.x.jar 1rm -rf /opt/module/apache-flume/lib/guava.1.x.jar åˆ é™¤è€ç‰ˆæœ¬æ¶åŒ…å†è¿è¡Œã€‚ @æ•°æ®é‡‡é›†flumeçš„æ•°æ®é‡‡é›†ï¼Œå¯ä»¥åœ¨flumeæ ¹ç›®å½•ä¸‹æ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹æ¥ä¿å­˜æ•°æ®é‡‡é›†çš„æ–‡ä»¶ï¼Œåˆ›å»ºflumeé‡‡é›†æ–‡ä»¶éœ€è¦ç”¨.confåšåç¼€å #åˆ›å»º12mkdir -p /opt/module/apache-flume/job/a1.confvi /opt/module/apache-flume/job/a1.conf #æ–‡ä»¶é…ç½®æ–¹æ³•ä¸€ï¼šexecç±»å‹1234567891011121314151617181920212223#ä½¿ç”¨s1ã€k1ã€c1ä»£è¡¨sourceã€sinkã€channela1.sources = s1a1.sinks = k1a1.channels = c1#descirbe/configuration the sourcea1.source.s1.type = exec#é‡‡é›†æ•°æ®çš„ä½ç½®ï¼Œé¢˜ç›®è¦æ±‚ä¸€èˆ¬æ˜¯namenodeæˆ–æ˜¯datanodeï¼Œå¦‚æœä½¿ç”¨æˆ–ï¼Œåˆ™ä¸¤ä¸ªéƒ½å¯a1.source.s1.command = tail -F /opt/module/hadoop/logs/hadoop-root-namenode-master.log#describe the sinka1.sinks.k1.type = hdfs#é‡‡é›†åå­˜å‚¨çš„ä½ç½®a1.sinks.k1.hdfs.path = hdfs://master:9000/flume1#use a channel which buffers events in memorya1.channels.c1.type = memorya1.channels.c1.capacity = 1000a1.channels.c1.transactionCapacity = 100#bind the source and sink to the channela1.sources.s1.channels = c1a1.sinks.k1.channel = c1 æ–¹æ³•äºŒï¼šTAILDIRç±»å‹1234567891011121314151617q1.sources = s1q1.sinks = k1q1.channels = c1 q1.sources.s1.type = TAILDIRq1.sources.s1.filegroups = f1q1.sources.s1.filegroups.f1 = /opt/module/hadoop/logs/.*log q1.sinks.k1.type = hdfsq1.sinks.k1.hdfs.path = hdfs://master:9000/flume2 q1.channels.c1.type = memoryq1.channels.c1.capacity = 1000q1.channels.c1.transactionCapacity = 100 q1.sources.s1.channels = c1q1.sinks.k1.channel = c1 æ ¹æ®æµ‹è¯•ï¼Œsinks.pathåé¢çš„åœ°å€è¦å’Œcore-site.xmlæ–‡ä»¶ä¸­çš„åœ°å€ä¸€æ ·ï¼Œåé¢çš„æ–‡ä»¶åè‡ªå®šä¹‰å³å¯ æ ¹æ®æµ‹è¯•ï¼Œæ ¹ç›®å½•ä¸‹ä¸åˆ›å»ºè¡¨ä¹Ÿå¯ä»¥è¿›è¡Œæ•°æ®é‡‡é›†ã€‚ #å¯åŠ¨é‡‡é›†é¦–å…ˆå¯åŠ¨hdfså’Œyarn å¯åŠ¨é‡‡é›†æ–‡ä»¶ 1bin/flume-ng agent --conf conf/ --name a1 --conf-file job/netcat-flume-logger.conf -Dflume.root.logger=INFO,console -Dflume.root.logger&#x3D;INFO,consoleè¡¨ç¤ºè¾“å‡ºé‡‡é›†è¿‡ç¨‹ï¼› â€“nameåé¢ä¸ºagentåå­—ï¼Œå³é…ç½®æ–‡ä»¶ä¸­æœ€å‰é¢çš„a1ï¼› â€“confåé¢ä¸ºflume&#x2F;confçš„è·¯å¾„åœ°å€ â€“conf-fileåé¢ä¸ºé¡¹ç›®æ–‡ä»¶åœ°å€ #æŸ¥çœ‹æ–‡ä»¶æŸ¥çœ‹é‡‡é›†çš„æ•°æ® 1hdfs dfs -ls -R /flume1 åˆ›å»ºè¡¨æ–‡ä»¶ 1hadoop fs -mkdir -p /flume æ ¹æ®æµ‹è¯•ï¼Œæ ¹ç›®å½•ä¸‹ä¸åˆ›å»ºè¡¨ä¹Ÿå¯ä»¥è¿›è¡Œæ•°æ®é‡‡é›†ã€‚å†™åœ¨è¿™é‡Œä»¥é˜²å¤–ä¸€éœ€è¦ã€‚","categories":["Flume"]},{"title":"Flinkæ­å»º","path":"/2024/04/25/flink-build/","content":"Flinké…ç½®è§£å‹æ–‡ä»¶ 1tar -zxvf /opt/software/flink -C /opt/module @é…ç½®ç¯å¢ƒ1234567vi /etc/profileexport FLINK_HOME=/opt/module/flinkexport PATH=$PATH:$FLINK_HOME/bin//ä»¥ä¸‹é…ç½®æ˜¯flink on yarnæ‰€éœ€è¦çš„é…ç½®å†…å®¹export HADOOP_CONF_DIR=/opt/module/hadoop/etc/hadoopexport HADOOP_CLASSPATH=`/opt/module/hadoop/bin/hadoop classpath`source /etc/profile @é…ç½®æ–‡ä»¶#flink-conf.yaml12vi /opt/module/flink/conf/flink-conf.yamljobmanager.rpc.address:master #masters12vi /opt/module/flink/conf/mastersmaster:8081 #workers123vi /opt/module/flink/conf/workersslave1slave2 @åˆ†å‘èŠ‚ç‚¹å’Œå¯åŠ¨é›†ç¾¤#åˆ†å‘èŠ‚ç‚¹12345scp -r /opt/module/flume slave1:/opt/modulescp -r /opt/module/flume slave2:/opt/modulescp -r /etc/profile slave1:/etcscp -r /etc/profile slave2:/etcsource /etc/profile #å¯åŠ¨é›†ç¾¤å¯åŠ¨é›†ç¾¤ 1start-cluster.sh å…³é—­é›†ç¾¤ 1stop-cluster.sh å¯åŠ¨resourcemanager 1yarn-daemon.sh start resourcemanager å¯åŠ¨nodemanager 1yarn-daemon.sh start nodemanager æ‰§è¡Œæµ‹è¯•ä»£ç  1flink run -m yarn-cluster -p 2 -yjm 2G -ytm 2G $FLINK_HOME/examples/batch/WordCount.jar @éƒ¨åˆ†æŠ¥é”™ æŠ¥é”™ å‡ºé”™åŸå› ï¼š ç±»åŠ è½½å™¨çš„ç›¸å…³æŠ¥é”™ï¼Œå¯èƒ½æ—¶ç±»åŠ è½½å™¨çš„é—®é¢˜ è§£å†³æ–¹æ³•ï¼š å¯ä»¥ä½¿ç”¨é…ç½®â€classloader.check-leaked-classloaderâ€œç¦ç”¨æ­¤æ£€æŸ¥ ç¼–è¾‘flink-conf.yaml 1classloader.check-leaked-classloader: false éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œfalseå‰éœ€è¦æœ‰ä¸€ä¸ªç©ºæ ¼é”®å ä½ç¬¦ï¼Œå¦åˆ™æ— æ³•ç”Ÿæ•ˆ","categories":["Flink"]},{"title":"Clickhouseæ­å»º","path":"/2024/04/25/clickhouse-build/","content":"ClickHouseæ­å»ºClickhouseæ­å»ºç®€è¿°clickhouseåœ¨è¿›è¡Œæ­å»ºæ—¶ï¼Œæ˜¯ä½¿ç”¨clickhouseè„šæœ¬è¿›è¡Œæ­å»ºï¼Œæ‰€ä»¥è§£å‹clickhouseæ–‡ä»¶åç›´æ¥è¿è¡Œæ–‡ä»¶çš„è„šæœ¬å³å¯ æ“ä½œæ­¥éª¤è§£å‹æ–‡ä»¶1234tar -zxvf /opt/software/clickhouse-common-static-dbg-21.9.4.3/ -C /opt/module/tar -zxvf /opt/software/clickhouse-common-static-21.9.4.35.tgz -C /opt/module/tar -zxvf /opt/software/clickhouse-server-21.9.4.35.tgz -C /opt/module/tar -zxvf /opt/software/clickhouse-client-21.9.4.35.tgz -C /opt/module/ clickhouseæœ‰ä»¥ä¸Šå››ä¸ªæ–‡ä»¶éœ€è¦è§£å‹ï¼Œè§£å‹æ— é¡ºåºè¦æ±‚ æ‰§è¡Œè„šæœ¬1234./clickhouse-common-static-dbg-21.9.4.3//install/doinst.sh ./clickhouse-common-static-21.9.4.35/install/doinst.sh ./clickhouse-client-21.9.4.35/install/doinst.sh./clickhouse-server-21.9.4.35/install/doinst.sh å››ä¸ªè„šæœ¬æ–‡ä»¶ä¸¥æ ¼æ„ä¹‰ä¸Šæ¥è¯´æ²¡æœ‰é¡ºåºï¼Œä¸€èˆ¬æ¥è¯´æ˜¯å…ˆæ‰§è¡Œä¸¤ä¸ªcommonæ–‡ä»¶ï¼Œå…¶æ¬¡æ˜¯clientå®¢æˆ·ç«¯æ–‡ä»¶ï¼Œæœ€åæ˜¯serveræœåŠ¡æ–‡ä»¶ã€‚ è¿™æ ·çš„é¡ºåºä¸»è¦æ˜¯æ–¹ä¾¿æˆªå›¾ã€‚ commonä¸clientæ–‡ä»¶æ‰§è¡Œåæ²¡æœ‰ç»“æœæ˜¾ç¤ºï¼Œserveræ–‡ä»¶æ‰§è¡Œåæœ‰ç»“æœæ˜¾ç¤ºï¼Œæ‰€ä»¥æœ€åä½¿ç”¨serveræ–‡ä»¶ å¯åŠ¨Clickhouseå¯åŠ¨ 1systemctl start clickhouse-server é‡å¯ 1systemctl restart clickhouse-server æŸ¥è¯¢çŠ¶æ€ 1systemctl status clickhouse-server è¿è¡ŒçŠ¶æ€ï¼š è¿è¡ŒçŠ¶æ€ç¤ºä¾‹ å…³é—­çŠ¶æ€ï¼š å…³é—­çŠ¶æ€ç¤ºä¾‹ å…³é—­ 1systemctl stop clickhouse-server ç™»å½•Clickhouse1clickhouse-client --port 9000 --host master --password 123456 clickhouseçš„é»˜è®¤ç«¯å£å·ä¸º9000ï¼Œä½†æ˜¯hadoop3.xç‰ˆæœ¬ä¸­çš„hadoopé»˜è®¤ç«¯å£ä¹Ÿæ˜¯9000ï¼Œæ‰€ä»¥ä¼šå‡ºç°ç«¯å£å ç”¨çš„æƒ…å†µï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ›´æ”¹clickhouseçš„é»˜è®¤ç«¯å£å·ä»¥æ­¤æ¥ä¿è¯ç«¯å£ä¸ä¼šå‡ºç°é‡å¤å ç”¨çš„æƒ…å†µã€‚ æ›´æ”¹Clickhouseç«¯å£å·æœç´¢test_shard_localhostï¼Œå…¶ä¸­æœ‰8ä¸ªç«¯å£ä¸º9000çš„æ–‡ä»¶éœ€è¦ä¿®æ”¹ä¸º9001ï¼› æ³¨æ„9440ç«¯å£æ–‡ä»¶ï¼Œå³test_shard_localhost_secureä¸éœ€è¦è¿›è¡Œä¿®æ”¹ï¼› ä»¥ä¸‹æ˜¯ä¿®æ”¹æ–‡ä»¶ï¼š 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107&gt; 590 &lt;remote_servers&gt;&gt; 591 &lt;!-- Test only shard config for testing distributed storage --&gt;&gt; 592 &lt;test_shard_localhost&gt;&gt; 593 &lt;!-- Inter-server per-cluster secret for Distributed queries&gt; 594 default: no secret (no authentication will be performed)&gt; 595 &gt; 596 If set, then Distributed queries will be validated on shards, so at least:&gt; 597 - such cluster should exist on the shard,&gt; 598 - such cluster should have the same secret.&gt; 599 &gt; 600 And also (and which is more important), the initial_user will&gt; 601 be used as current user for the query.&gt; 602 &gt; 603 Right now the protocol is pretty simple and it only takes into account:&gt; 604 - cluster name&gt; 605 - query&gt; 606 &gt; 607 Also it will be nice if the following will be implemented:&gt; 608 - source hostname (see interserver_http_host), but then it will depends from DNS,&gt; 609 it can use IP address instead, but then the you need to get correct on the initiator node.&gt; 610 - target hostname / ip address (same notes as for source hostname)&gt; 611 - time-based security tokens&gt; 612 --&gt;&gt; 613 &lt;!-- &lt;secret&gt;&lt;/secret&gt; --&gt;&gt; 614 &gt; 615 &lt;shard&gt;&gt; 616 &lt;!-- Optional. Whether to write data to just one of the replicas. Default: false (write data to all replicas). --&gt;&gt; 617 &lt;!-- &lt;internal_replication&gt;false&lt;/internal_replication&gt; --&gt;&gt; 618 &lt;!-- Optional. Shard weight when writing data. Default: 1. --&gt;&gt; 619 &lt;!-- &lt;weight&gt;1&lt;/weight&gt; --&gt;&gt; 620 &lt;replica&gt;&gt; 621 &lt;host&gt;localhost&lt;/host&gt;&gt; 622 &lt;port&gt;9001&lt;/port&gt;&gt; 623 &lt;!-- Optional. Priority of the replica for load_balancing. Default: 1 (less value has more priority). --&gt;&gt; 624 &lt;!-- &lt;priority&gt;1&lt;/priority&gt; --&gt;&gt; 625 &lt;/replica&gt;&gt; 626 &lt;/shard&gt;&gt; 627 &lt;/test_shard_localhost&gt;&gt; 628 &lt;test_cluster_two_shards_localhost&gt;&gt; 629 &lt;shard&gt;&gt; 630 &lt;replica&gt;&gt; 631 &lt;host&gt;localhost&lt;/host&gt;&gt; 632 &lt;port&gt;9001&lt;/port&gt;&gt; 633 &lt;/replica&gt;&gt; 634 &lt;/shard&gt;&gt; 635 &lt;shard&gt;&gt; 636 &lt;replica&gt;&gt; 637 &lt;host&gt;localhost&lt;/host&gt;&gt; 638 &lt;port&gt;9001&lt;/port&gt;&gt; 639 &lt;/replica&gt;&gt; 640 &lt;/shard&gt;&gt; 641 &lt;/test_cluster_two_shards_localhost&gt;&gt; 642 &lt;test_cluster_two_shards&gt;&gt; 643 &lt;shard&gt;&gt; 644 &lt;replica&gt;&gt; 645 &lt;host&gt;127.0.0.1&lt;/host&gt;&gt; 646 &lt;port&gt;9001&lt;/port&gt;&gt; 647 &lt;/replica&gt;&gt; 648 &lt;/shard&gt;&gt; 649 &lt;shard&gt;&gt; 650 &lt;replica&gt;&gt; 651 &lt;host&gt;127.0.0.2&lt;/host&gt;&gt; 652 &lt;port&gt;9001&lt;/port&gt;&gt; 653 &lt;/replica&gt;&gt; 654 &lt;/shard&gt;&gt; 655 &lt;/test_cluster_two_shards&gt;&gt; 656 &lt;test_cluster_two_shards_internal_replication&gt;&gt; 657 &lt;shard&gt;&gt; 658 &lt;internal_replication&gt;true&lt;/internal_replication&gt;&gt; 659 &lt;replica&gt;&gt; 660 &lt;host&gt;127.0.0.1&lt;/host&gt;&gt; 661 &lt;port&gt;9001&lt;/port&gt;&gt; 662 &lt;/replica&gt;&gt; 663 &lt;/shard&gt;&gt; 664 &lt;shard&gt;&gt; 665 &lt;internal_replication&gt;true&lt;/internal_replication&gt;&gt; 666 &lt;replica&gt;&gt; 667 &lt;host&gt;127.0.0.2&lt;/host&gt;&gt; 668 &lt;port&gt;9001&lt;/port&gt;&gt; 669 &lt;/replica&gt;&gt; 670 &lt;/shard&gt;&gt; 671 &lt;/test_cluster_two_shards_internal_replication&gt;&gt; 672 &lt;test_shard_localhost_secure&gt;&gt; 673 &lt;shard&gt;&gt; 674 &lt;replica&gt;&gt; 675 &lt;host&gt;localhost&lt;/host&gt;&gt; 676 &lt;port&gt;9440&lt;/port&gt;&gt; 677 &lt;secure&gt;1&lt;/secure&gt;&gt; 678 &lt;/replica&gt;&gt; 679 &lt;/shard&gt;&gt; 680 &lt;/test_shard_localhost_secure&gt;&gt; 681 &lt;test_unavailable_shard&gt;&gt; 682 &lt;shard&gt;&gt; 683 &lt;replica&gt;&gt; 684 &lt;host&gt;localhost&lt;/host&gt;&gt; 685 &lt;port&gt;9001&lt;/port&gt;&gt; 686 &lt;/replica&gt;&gt; 687 &lt;/shard&gt;&gt; 688 &lt;shard&gt;&gt; 689 &lt;replica&gt;&gt; 690 &lt;host&gt;localhost&lt;/host&gt;&gt; 691 &lt;port&gt;1&lt;/port&gt;&gt; 692 &lt;/replica&gt;&gt; 693 &lt;/shard&gt;&gt; 694 &lt;/test_unavailable_shard&gt;&gt; 695 &lt;/remote_servers&gt; éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä»ç½‘ä¸Šæœç´¢çš„ä¿®æ”¹clickhouseç«¯å£å·æ˜¯ï¼ˆ82è¡Œï¼ŒæŸ¥æ‰¾&lt;tcp_port&gt;å³å¯æ‰¾åˆ°ï¼‰ï¼š 1&gt; 82 &lt;tcp_port&gt;9001&lt;/tcp_port&gt; åˆ é™¤ç›‘å¬æ–‡ä»¶1rm -rf /etc/clickhouse-server/config.d/listen.xml æ³¨æ„äº‹é¡¹ ç›‘å¬æ–‡ä»¶listen.xml åœ¨æ‰§è¡Œ./clickhouse-server-21.9.4.35/install/doinst.sh æ—¶ï¼Œä¼šéœ€è¦è¾“å…¥clickhouseçš„ç™»é™†å¯†ç ï¼Œå¦‚æœæ­¤æ—¶ä¸è¾“å…¥å¯†ç ï¼Œå°±ä¸ä¼šå‡ºç°ç›‘å¬æ–‡ä»¶ã€‚","categories":["Clickhouse"]},{"title":"æ•°æ®å¯è§†åŒ–ï¼ˆJavaSciptï¼‰","path":"/2024/04/25/æ•°æ®å¯è§†åŒ–ï¼ˆJSï¼‰/","content":"ä¸€äº›å…³äºè‡ªå·±å­¦ä¹ çš„å†…å®¹ï¼Œå¸Œæœ›èƒ½å¯¹ä½ æœ‰å¸®åŠ©~ ğŸ’¯èµ›å‰æ•´ç†ğŸ¥‡æ•°æ®å¯è§†åŒ–ğŸ•å‰ç½®é…ç½® ğŸš©vue.config.js ğŸ¤å…³é—­è¯­æ³•æ£€æµ‹1lintOnSave:false æ²¡æœ‰å…³é—­è¯­æ³•æ£€æµ‹ä¼šå¯¼è‡´echartså¼•ç”¨æ—¶å‡ºç°æŠ¥é”™ï¼Œæ‰€ä»¥é¦–å…ˆéœ€è¦é…ç½®çš„ä¿¡æ¯æ˜¯å…³é—­è¯­æ³•æ£€æµ‹ ğŸ˜è·¨åŸŸ123456789101112devServer:&#123; proxy:&#123; &quot;/api&quot;:&#123; target:&quot;æ¥å£åœ°å€&quot;, ws:true, changeOrigin:true, pathRewrite;&#123; &quot;^/api&quot;:&quot;&quot; &#125; &#125; &#125;&#125; targetï¼šæ¥å£çš„åœ°å€ï¼Œä¼šç»™å®šæ•°æ®æ¥å£ã€‚ wsï¼šwebstocketåè®®ï¼ŒåŒå‘é€šé“ï¼Œåœ¨ä¼ è¾“é€Ÿåº¦ä¸Šä¼˜äºhttpåè®®ã€‚ changeOriginï¼šdevServerä¸­ï¼Œproxyçš„changeOriginæ˜¯falseï¼šchangeOriginè¯·æ±‚å¤´ä¸­hostä»ç„¶æ˜¯æµè§ˆå™¨å‘é€è¿‡æ¥çš„hostï¼›å¦‚æœè®¾ç½®æˆtrueï¼šå‘é€è¯·æ±‚å¤´ä¸­hostä¼šè®¾ç½®æˆtargetã€‚åœ¨vue-cli3ä¸­ï¼Œé»˜è®¤changeOriginçš„å€¼æ˜¯true,æ„å‘³ç€hostè®¾ç½®æˆtargetï¼Œè¿™ä¸cue-cli2ä¸ä¸€è‡´ï¼Œvue-cli2è¿™ä¸ªé»˜è®¤å€¼æ˜¯falseã€‚ pathRewriteï¼šé‡å†™ç­–ç•¥ï¼Œåœ¨targetåä¼šå­˜åœ¨å…¶ä»–å‚æ•°ï¼Œä»¥&#x2F;apiå»æ·»åŠ ï¼Œä½†æ˜¯æ·»åŠ åˆ°å…·ä½“çš„æ¥å£ä¸­æ²¡æœ‰&#x2F;apiè¿™å‡ ä¸ªå­—ç¬¦ï¼Œæ‰€ä»¥éœ€è¦æ·»åŠ ä¸€ä¸ªç©ºå­—ç¬¦ä¸²åœ¨ä¼ å…¥å‚æ•°çš„æ—¶å€™ä»£æ›¿&#x2F;apiã€‚ ğŸš©å…¨å±€é…ç½® ğŸ¤”æ•°æ®è¯·æ±‚postè¯·æ±‚å’Œgetè¯·æ±‚ï¼Œä¸¤ä¸ªè¯·æ±‚æ–¹å¼çš„è¯·æ±‚æ–¹æ³•å¤§è‡´ç›¸åŒï¼Œåœ¨è¯·æ±‚æ—¶ï¼Œmethodå‚æ•°å†…æ ¹æ®å¡«å…¥çš„å‚æ•°ä¸åŒæ¥è¿›è¡Œä¸åŒçš„è¯·æ±‚ã€‚ postè¯·æ±‚æœ‰è¯·æ±‚ä½“ï¼Œåœ¨å®‰å…¨æ–¹é¢è¦é«˜äºgetè¯·æ±‚ 1234axios:(&#123; method:&quot;get&quot;, url:&quot;/api/å‚æ•°api&quot;&#125;) ä½¿ç”¨axiosè¿›è¡Œæ•°æ®è¯·æ±‚ï¼Œåœ¨è¯·æ±‚å‰ï¼Œå¯ä»¥åˆ©ç”¨postmanå·¥å…·è¿›è¡Œæ•°æ®æ¥å£çš„è°ƒç”¨ï¼Œæ£€æŸ¥æ— è¯¯åä½¿ç”¨axiosè¿›è¡Œæ•°æ®è¯·æ±‚ã€‚getè¯·æ±‚éœ€è¦é…ç½®å‚æ•°methodå’Œå‚æ•°urlã€‚å‰è€…æ˜¯è¯·æ±‚ç±»å‹ï¼Œåè€…æ˜¯apiå‚æ•°ã€‚ 12345678axios:(&#123; method:&quot;post&quot;, url:&quot;/api/å‚æ•°api&quot;, data:&#123; startTime: yyyy.MM.dd, endTime: yyyy.MM.dd &#125;&#125;) postè¯·æ±‚ç›¸å¯¹äºgetè¯·æ±‚å¤šäº†ä¸€ä¸ªbodyè¯·æ±‚ä½“çš„å†…å®¹ï¼Œè¯¥å†…å®¹å­˜æ”¾åœ¨dataå‚æ•°ä¸­ï¼Œä¹Ÿå°±æ˜¯éœ€è¦é¢å¤–åŠ å…¥çš„å†…å®¹ã€‚ åœ¨postmanä¸­ï¼Œéœ€è¦æ ¹æ®é¢˜ç›®æ¥è¿›è¡Œè®¾ç½®ï¼Œä¸€èˆ¬bodyä¸­ï¼Œä¼ å…¥çš„å‚æ•°ç±»å‹ä¸ºjsonç±»å‹ï¼Œè¿”å›ç±»å‹ä¹Ÿä¸ºjsonç±»å‹ã€‚ ğŸ•‘ç”µå•† ğŸš©æŸ±çŠ¶å›¾ ğŸ˜æ•°æ®å¤„ç† ğŸ¤‘æ¶ˆè´¹é¢æœ€é«˜&#x2F;æœ€ä½çš„çœä»½&#x2F;åœ°åŒº éœ€æ±‚åˆ†æï¼šå­—æ®µé€‰æ‹©æ¶ˆè´¹é¢ã€çœä»½&#x2F;åœ°åŒºã€‚æ±‚æ¶ˆè´¹é¢çš„æœ€å¤§å’Œæœ€å°å€¼çš„æ€»å’Œï¼Œå•ä¸€ç´¯åŠ å¤„ç†ï¼Œè€ƒè™‘ä½¿ç”¨Mapå¯¹è±¡çš„getå’Œsetæ–¹æ³•æ¥æ‹¿åˆ°æ¶ˆè´¹é¢æ€»é¢ã€‚ç´¯åŠ åéœ€è¦è¿›è¡Œæ’åºï¼Œmapæ²¡æœ‰å†…ç½®çš„æ’åºæ–¹æ³•ï¼Œå°†mapå¯¹è±¡è½¬ä¸ºæ•°ç»„åè¿›è¡Œæ’åºå¤„ç†ï¼Œå–å‰å‡ ä½æˆ–åå‡ ä½ä½¿ç”¨spliceæ–¹æ³•è¿›è¡Œç­›é€‰ã€‚ ç´¯åŠ å¤„ç†ï¼š 1234567891011//ç´¯åŠ å¤„ç† åˆ©ç”¨mapå¯¹è±¡çš„setå’Œgetæ–¹æ³•var map1 = new Map()data.forEach((e) =&gt;&#123; //åˆ¤æ–­å¯¹è±¡ä¸­æ˜¯å¦å«æœ‰çœä»½å­—æ®µï¼Œå¦‚æœæœ‰ï¼Œåˆ™è¿›è¡Œç´¯åŠ ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™ä¼ å…¥ç¬¬ä¸€ä¸ªå‚æ•° if(map1.has(e.proviceName))&#123; var tmp = map1.get(e.proviceName) + e.consumptionAmount map1.set(e.proviceName , tmp) &#125;else&#123; map1.set(e.proviceName , e.consumptionAmount) &#125;&#125;) æ’åºç­›é€‰å¤„ç†ï¼š 12345678//å¯¹è±¡è½¬ä¸ºæ•°ç»„map1 = Array.from(map1)map1.sort((a,b) =&gt;&#123; //é™åºï¼Œå‡åºå†™æ³•åˆ™ç›¸åï¼Œå› ä¸ºä¸ºäºŒç»´æ•°ç»„ï¼Œå¤„ç†æ•°æ®ä¸ºç¬¬äºŒä½ï¼Œæ‰€ä»¥è¿”å›ä¸‹æ ‡ä¸º1 //sort()æ–¹æ³•å†™æ³•å¿…é¡»æ˜¯returnè¿”å›ï¼Œå¦åˆ™ä¸ä¼šè¿›è¡Œå¤„ç† return b[1] - a[1]&#125;).splice(5)//ç»§ç»­ä½¿ç”¨splice()æ–¹æ³•ç­›é€‰å‡ºå‰äº”çš„æ•°æ® ğŸ˜å„ä¸ªçœä»½&#x2F;åœ°åŒºæ¶ˆè´¹é¢çš„å¹³å‡æ•° éœ€æ±‚åˆ†æï¼šé€‰æ‹©å­—æ®µçœä»½&#x2F;åœ°åŒºã€æ¶ˆè´¹é¢ã€‚éœ€è¦æ±‚å¹³å‡çš„æ¶ˆè´¹é¢ï¼Œåªéœ€è¦ä½¿ç”¨mapæ–¹æ³•æå–åˆ°å¯¹åº”æ¶ˆè´¹é¢çš„æ¯ä¸€æ¡æ•°æ®ï¼Œç„¶åå°†æ‰€æœ‰æ•°æ®ç´¯åŠ å†é™¤ä»¥æ•°æ®æ¡æ•°ï¼ŒåŒæ—¶åœ¨è¿™ä¸€æ­¥å¯ä»¥è¿›è¡Œä¿ç•™å°æ•°ç‚¹çš„æ“ä½œï¼Œå³å¯ç®—å‡ºæ­¤çœä»½&#x2F;åœ°åŒºçš„å¹³å‡æ¶ˆè´¹é¢ã€‚ æå–æ•°æ®åˆ°æ•°ç»„ä¸­ï¼š 1234567891011121314var map1 = new Map()data.forEach((e) =&gt;&#123; if(map1.has(e.proviceName))&#123; //å’Œç´¯åŠ ç±»ä¼¼ï¼Œåªæ˜¯æ­¤æ—¶ä¼ å…¥çš„mapå¯¹è±¡ä¸­ï¼Œå¯¹åº”çš„valueå€¼æ˜¯ä¸€ä¸ªæ•°ç»„ã€‚ var tmp1 = [] tmp1 = map1.get(e.proviceName) tmp1.push(e.consumptionAmount) map1.set(e.proviceName , tmp1) &#125;else&#123; //è¿™é‡Œå¦‚æœç¬¬äºŒä½ä¸ç”¨[]åŒ…è£¹ï¼Œtmp1æ— æ³•pushä»»ä½•æ•°æ® //å¦‚æœè¿™é‡Œä¸ç”¨[]åŒ…è£¹ï¼Œåˆ™éœ€è¦å®šä¹‰ä¸€ä¸ªæ•°ç»„æ¥æ¥æ”¶[e.consumptionAount] map.set(e.proviceName , [e.consumptionAmount]) &#125;&#125;) æ±‚å¹³å‡æ•°å¤„ç†ï¼š 12345678910111213//å®šä¹‰ä¸€ä¸ªæ•°ç»„æ¥æ”¶é›†æ±‚å¹³å‡å€¼åçš„æ•°æ®var compare = [] map1.forEach((v,k))&#123; var sum = 0 v.forEach((e) =&gt;&#123; //æ±‚æ€»æ•° sum += e &#125;) //æ±‚å¹³å‡æ•°ï¼ŒåŒæ—¶ä¿ç•™ä¸¤ä½å°æ•° var avgNum = (sum / v.length).toFixed(2) compare.push(&#123;provice:k , avg:avgNum&#125;)&#125; forEachï¼šforEachæœ‰ä¸‰ä¸ªå‚æ•°ï¼Œï¼ˆvalueï¼Œkeyï¼Œitemï¼‰ï¼Œé»˜è®¤ä¼ å‚ä¸ºvalueã€‚å…¶ä¸­ï¼Œvalueä»£è¡¨çš„æ˜¯å…ƒç´ ï¼Œkeyä»£è¡¨çš„æ˜¯å…ƒç´ ç´¢å¼•ï¼Œå³ä¸‹æ ‡ï¼Œitemä»£è¡¨çš„æ˜¯æ•´ä¸ªæ•°ç»„æˆ–è€…å¯¹è±¡ã€‚å½“ä¼ ä¸€ä¸ªå‚æ•°æ˜¯ï¼Œä»£è¡¨çš„å°±æ˜¯å…¶æœ¬èº«ï¼›å½“ä¼ ä¸¤ä¸ªå‚æ•°æ—¶ï¼Œç¬¬ä¸€ä¸ªå‚æ•°ä»£è¡¨å…¶å…ƒç´ æœ¬èº«ï¼Œç¬¬äºŒä¸ªå‚æ•°ä»£è¡¨ä¸‹æ ‡ï¼Œå½“ä¼ å‚å¯¹è±¡æ˜¯ä¸€ä¸ªå¯¹è±¡æ—¶ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œkeyå¯¹åº”keyï¼Œvalueå¯¹åº”valueï¼Œæ‰€ä»¥ä¼ å‚ä¸­ç¬¬ä¸€ä¸ªå‚æ•°ä¸ºå€¼ï¼Œç¬¬äºŒä¸ªå‚æ•°ä¸ºé”®ã€‚ æ’åºç­›é€‰å¤„ç†ï¼š 1234compare.sort((a,b) =&gt;&#123; //æ ¹æ®avgå­—æ®µè¿›è¡Œæ’åº return b.avg - a.avg&#125;).splice(5) ğŸ¤¨å„ä¸ªçœä»½&#x2F;åœ°åŒºæ¶ˆè´¹é¢çš„ä¸­ä½æ•° éœ€æ±‚åˆ†æï¼šé€‰æ‹©å­—æ®µçœä»½&#x2F;åœ°åŒºã€æ¶ˆè´¹é¢ã€‚ä¸­ä½æ•°éœ€è¦ç”¨mapæå–åˆ°æ‰€æœ‰çš„æ¶ˆè´¹é¢æ•°æ®ï¼Œç„¶åå†å¯¹æ•°ç»„è¿›è¡ŒäºŒæ¬¡å¤„ç†ï¼Œé¦–å…ˆå…ˆå¯¹æ•°ç»„è¿›è¡Œæ’åºï¼Œç„¶åå†å–åˆ°ä¸­ä½æ•°ã€‚ æå–æ•°æ®åˆ°æ•°ç»„ä¸­ï¼š 1234567891011121314var map1 = new Map()data.forEach((e) =&gt;&#123; if(map1.has(e.proviceName))&#123; //å’Œç´¯åŠ ç±»ä¼¼ï¼Œåªæ˜¯æ­¤æ—¶ä¼ å…¥çš„mapå¯¹è±¡ä¸­ï¼Œå¯¹åº”çš„valueå€¼æ˜¯ä¸€ä¸ªæ•°ç»„ã€‚ var tmp1 = [] tmp1 = map1.get(e.proviceName) tmp1.push(e.consumptionAmount) map1.set(e.proviceName , tmp1) &#125;else&#123; //è¿™é‡Œå¦‚æœç¬¬äºŒä½ä¸ç”¨[]åŒ…è£¹ï¼Œtmp1æ— æ³•pushä»»ä½•æ•°æ® //å¦‚æœè¿™é‡Œä¸ç”¨[]åŒ…è£¹ï¼Œåˆ™éœ€è¦å®šä¹‰ä¸€ä¸ªæ•°ç»„æ¥æ¥æ”¶[e.consumptionAount] map1.set(e.proviceName , [e.consumptionAmount]) &#125;&#125;) æ’åºå¹¶æ±‚ä¸­ä½æ•°ï¼š 12345678910111213141516171819202122//tmp1æ•°ç»„ç”¨æ¥æ‹¿åˆ°å‰äº”çœä»½çš„ä¸­ä½æ•°var tmp1 = []map1.forEach((v,k) =&gt;&#123; //æ’åºæ“ä½œ v.sort((a,b) =&gt;&#123; return b - a &#125;) //æ±‚ä¸­ä½æ•° v.every(() =&gt;&#123; //å¦‚æœæ˜¯å–ä½™ä¸ºå¶æ•°ï¼Œåˆ™ä¸­ä½æ•°ä¸ºå–å•†å’Œå•†å°ä¸€ä½çš„æ•°å€¼ç›¸åŠ æ±‚å¹³å‡å€¼ if(v.length % 2 == 0)&#123; var tmp2 = ((v[v.length / 2] + v[v.length / 2 - 1]) / 2).toFixed(2) tmp1.push(&#123;province:k , mid:tmp2&#125;) return false &#125;else&#123; var tmp2 = v[Math.floor(v.length / 2).toFixed(2)] tmp1.push(&#123;province:k , mid:tmp2&#125;) //forEachéå†æ²¡æœ‰breakå’Œcontinueï¼Œå¯ä»¥ä½¿ç”¨everyè¿›è¡Œä»£æ›¿ï¼Œreturn falseè¿”å›falseï¼Œç­‰æ•ˆäºbreak return false &#125; &#125;)&#125;) breakï¼šforEachéå†æ–¹æ³•ä¸­ä¸æ”¯æŒbreakå’Œcontinueï¼Œå¦‚æœéœ€è¦ä½¿ç”¨continueæ—¶ï¼Œå¯ä»¥é‡‡ç”¨return falseæˆ–return trueä»£æ›¿ï¼Œå¦‚æœè¦ä½¿ç”¨breakæ—¶ï¼Œå¯ä»¥ä½¿ç”¨try catchæˆ–everyæˆ–someä»£æ›¿ã€‚å®æµ‹return falseå¯ä»¥è¾¾åˆ°breakè¦æ±‚ã€‚ æ’åºç­›é€‰å¤„ç†ï¼š 123tmp1.sort((a,b) =&gt;&#123; return b.mid - a.mid&#125;).splice(5) ğŸ˜å…¨å±€æ ·å¼ xAxis typeï¼šcategory &#x2F; value dataï¼šxdata &#x2F; âŒ axisLabelï¼šrotate:50 &#x2F; fontSize:18 yAxis typeï¼šcategory &#x2F; value dataï¼šxdata &#x2F; âŒ scaleï¼štrue series typeï¼šbar dataï¼šydata labelï¼šshow:true &#x2F; position:direction ğŸš©æŠ˜çº¿å›¾ ğŸ˜‚æ•°æ®å¤„ç† ğŸ˜Œæ¯å¹´ä¸Šæ¶å•†å“æ•°é‡å˜åŒ– æ•°æ®åˆ†æï¼šå­—æ®µé€‰æ‹©å¹´ä»½ã€å•†å“åç­‰ä»»æ„å­—æ®µã€‚ç›¸å¯¹äºä½¿ç”¨è®¡æ•°çš„æ–¹æ³•ï¼Œå…¶å®é€šè¿‡mapå¯¹è±¡ä¸­getæ–¹æ³•ç»Ÿè®¡å‡ºç°æ¬¡æ•°ï¼Œç„¶åç»Ÿè®¡mapå¯¹è±¡ä¸­æ•°ç»„çš„é•¿åº¦ï¼Œå³å¯è¾¾åˆ°ç»Ÿè®¡ä¸Šæ¶å•†å“æ•°é‡çš„å˜åŒ–ã€‚ ç»Ÿè®¡å„å¹´ä»½æ•°æ®ï¼š 12345678910var map1 = new Map()data.forEach((e) =&gt;&#123; if(map1.has(e.year))&#123; var tmp1 = [] tmp1 = map1.get(e.year) tmp1.push(e.id) map1.set(e.year , tmp1) &#125;else map1.set(e.year , [e.id])&#125;) ç»Ÿè®¡é•¿åº¦ï¼š 123456var xdata = []var ydata = []map.forEach((v,k) =&gt;&#123; xdata.push(k) ydata.push(v.length)&#125;) ğŸ¤ªå…¨å±€æ ·å¼ xAxis typeï¼šcategory dataï¼šxdata axisLabelï¼šrotate:50 &#x2F; fontSize:18 yAxis typeï¼š value dataï¼šxdata scaleï¼štrue series typeï¼šline dataï¼šydata labelï¼šshow:true &#x2F; position:direction ğŸš©æŠ˜æŸ±æ··åˆå›¾ ğŸ˜æ•°æ®å¤„ç† ğŸ¤¯æŸ±çŠ¶å›¾è¡¨ç¤ºå‰äº”çœä»½å¹³å‡æ¶ˆè´¹é¢ï¼ŒæŠ˜çº¿å›¾è¡¨ç¤ºå¯¹åº”åœ°åŒºçš„å¹³å‡æ¶ˆè´¹é¢ éœ€æ±‚åˆ†æï¼šå­—æ®µé€‰æ‹©çœä»½ã€åœ°åŒºã€æ¶ˆè´¹é¢ã€‚æœ¬é¢˜éš¾ç‚¹ä¸ºå¦‚ä½•å¯¹åº”çœä»½å’Œåœ°åŒºï¼Œå› ä¸ºå¯¹åº”ï¼ˆä¸»é”®ï¼‰å­—æ®µä¸ºçœä»½å­—æ®µï¼Œæ‰€ä»¥æ ¹æ®çœä»½æ¥è¿›è¡Œç­›é€‰ã€‚map1:{çœä»½ &#x3D;&gt; çœä»½æ€»é¢}ï¼Œmap2:{åœ°åŒº &#x3D;&gt; åœ°åŒºæ€»é¢}ï¼Œmap3:{åœ°åŒº &#x3D;&gt; åœ°åŒºå†…çœä»½ä¸ªæ•°}ã€‚ç”¨map1å¯¹è±¡è¿›è¡Œéå†ï¼Œç›®æ ‡å€¼æ˜¯æ‹¿åˆ°æ¯ä¸€ä¸ªçœä»½çš„åå­—ï¼Œå†æ¬¡å¯¹å…ƒæ•°æ®è¿›è¡Œéå†ï¼Œå¦‚æœçœä»½idå’Œå…ƒæ•°æ®ä¸­çš„çœä»½idç›¸ç­‰æ—¶ï¼Œé‚£ä¹ˆå¯¹çœä»½è®¡æ•°ï¼ŒåŒæ—¶æå–å‡ºå…ƒæ•°æ®ä¸­çš„åœ°åŒºåç§°ã€‚å°†åœ°åŒºæ”¾å…¥map2å’Œmap3ä¸­è¿›è¡Œå¯¹åº”è®¡ç®—å¹³å‡æ¶ˆè´¹é¢ï¼Œæ ¹æ®çœä»½è®¡æ•°å’Œmap1ä¸­çš„çœä»½æ€»é”€å”®é¢è¿›è¡Œè®¡ç®—å¹³å‡æ¶ˆè´¹é¢ã€‚ map1ï¼š 12345678var map1 = new Map()tmp1.forEach((e) =&gt;&#123; if(map1.has(e.province))&#123; tmp1.set(e.province , tmp1.get(e.province) + e.finalTotalAmount) &#125;else&#123; tmp1.set(e.province , e.finalTotalAmount) &#125;&#125;) map2å’Œmap3ï¼š 12345678910var map1 = new Map()tmp1.forEach((e) =&gt;&#123; if(map1.has(e.regionName))&#123; tmp2.set(e.regionName , tmp2.get(e.regionName) + e.finalTotalAmount) tmp3.set(e.regionName , tmp3.get(e.regionName) + 1) &#125;else&#123; tmp2.set(e.regionName , e.finalTotalAmount) tmp3.set(e.regionName , Number(1)) &#125;&#125;) å¯¹åº”çœä»½å’Œåœ°åŒºå¹¶æ±‚å¹³å‡æ¶ˆè´¹é¢ï¼š 1234567891011121314151617181920212223var res = []map1.for((v,k) =&gt;&#123; //ç¬¬ä¸€æ­¥æ˜¯æå–éœ€è¦çš„æ•°æ® //æå–çœä»½ var pro = k //å®šä¹‰è®¡æ•°å™¨ var count = 0 //å®šä¹‰ä¸€ä¸ªåœ°åŒºå€¼ç”¨äºæ¥æ”¶â€œçœä»½å¯¹åº”åœ°åŒºâ€ var reg_compare //æå–çœä»½å¯¹åº”æ¶ˆè´¹æ€»é¢ï¼Œè®¡ç®—éœ€è¦ä½¿ç”¨ var pro_v = v //è¿›å…¥å…ƒæ•°æ®å¼€å§‹åˆ¤æ–­ tmp1.forEach((e) =&gt;&#123; if(e.provinceName == pro)&#123; count += 1 reg_compare = e.regionName &#125; &#125;) //è®¡ç®— var pro_avg = (pro_v / count).toFixed(2) var reg_avg = (map2.get(reg_compare) / map3.get(reg_compare)).toFixed(2) res.push(&#123;pro:pro , reg:reg_compare , pro_avg:pro_avg , reg_avg:reg_avg&#125;)&#125;) æ’åºç­›é€‰å¤„ç†ï¼š 123res.sort((a,b) =&gt;&#123; return b.pro_avg - a.pro_avg&#125;).splice(5) ğŸ¥´å…¨å±€æ ·å¼ xAxis typeï¼šcategory dataï¼šxdata axisLabelï¼šrotate:50 &#x2F; fontSize:18 yAxis typeï¼š value dataï¼šxdata scaleï¼štrue legend dataï¼š[] &#x2F; âŒ series typeï¼šline ï¼† bar dataï¼šydata labelï¼šshow:true &#x2F; position:direction nameï¼š[â€œå›¾ä¾‹â€] ğŸš©é¥¼çŠ¶å›¾ ğŸ˜œæ•°æ®å¤„ç† ğŸ˜´é¥¼çŠ¶å›¾å±•ç¤ºå„åœ°åŒºæ¶ˆè´¹èƒ½åŠ› éœ€æ±‚åˆ†æï¼šæ±‚å„åœ°åŒºçš„æ¶ˆè´¹èƒ½åŠ›ï¼Œå³ä»¥åœ°åŒºä¸ºä¸»é”®å­—æ®µï¼Œç»Ÿè®¡æ­¤åœ°åŒºæ‰€æœ‰çš„æ¶ˆè´¹é‡‘é¢&#x2F; ç»Ÿè®¡ï¼š 12345678var map1 = new Map()tmp1.forEach((e) =&gt;&#123; if(map1.has(e.regionName))&#123; map1.set(e.regionName , map1.get(e.regionName) + e.finalTotalAmount) &#125;else&#123; map1.set(e.regionName , e.finalTotalAmount) &#125;&#125;) ğŸ¥±ç«ç‘°å›¾å±•ç¤ºå„åœ°åŒºå¹³å‡æ¶ˆè´¹èƒ½åŠ› éœ€æ±‚åˆ†æï¼šæ±‚å„åœ°åŒºçš„æ¶ˆè´¹èƒ½åŠ›ï¼Œå³ä»¥åœ°åŒºä¸ºä¸»é”®å­—æ®µï¼Œç»Ÿè®¡æ­¤åœ°åŒºæ‰€æœ‰çš„æ¶ˆè´¹é‡‘é¢çš„å¹³å‡é¢ æ±‚å„åœ°åŒºçš„æ¶ˆè´¹æ•°ç»„ï¼š 1234567891011var map1 = new Map()tmp1.forEach((e) =&gt;&#123; if(map1.has(e.regionName))&#123; var tmp2 = [] tmp2 = map1.get(e.regionName) tmp2.push(e.finalTotalAmount) map1.set(e.regionName , tmp2) &#125;else&#123; map1.set(e.regionName , [e.finalTotalAmount]) &#125;&#125;) æ±‚å¹³å‡é¢ï¼š 123456789var res = []map1.forEach((v,k) =&gt;&#123; var sum = 0 v.forEach(() =&gt;&#123; sum += 1 &#125;) var avg = (sum / v.length).toFixed(2) res.push(&#123;value:k , name:avg&#125;)&#125;) ğŸ¤¤å…¨å±€æ ·å¼ series dataï¼š[{valueï¼šxxï¼Œnameï¼šxx}] itemStyleï¼šnormalï¼š{labelï¼š{showï¼štrue ï¼Œ formatterï¼šâ€ {a} {b} {c} {d}%â€}} roseTypeï¼šradius &#x2F; area legend dataï¼š[] &#x2F; âŒ ğŸš©æ•£ç‚¹å›¾ ğŸ˜¤æ•°æ®å¤„ç† ğŸ‘¹æ•£ç‚¹å›¾å±•ç¤ºæ¯å¹´ä¸Šæ¶å•†å“æ•°é‡çš„å˜åŒ– ğŸ‘ºæ•£ç‚¹å›¾å±•ç¤ºçœä»½å¹³å‡æ¶ˆè´¹é¢ ğŸ˜¬å…¨å±€æ ·å¼ xAxis typeï¼šcategory &#x2F; value dataï¼šxdata axisLabelï¼šrotate:50 &#x2F; fontSize:18 yAxis typeï¼š value &#x2F; category dataï¼šxdata scaleï¼štrue series typeï¼šscatter labelï¼šshowï¼štrueï¼Œpositionï¼šdirection ğŸ•’å·¥ä¸š ğŸ˜®â€ğŸ’¨æ•°æ®å¤„ç†æ–¹æ³• ğŸš©å…ƒæ•°æ®ç­›é€‰.filter() 12345var dataOrigin = arr.data.filter((e) =&gt; (i.ChangeStartTime.split(&quot;T&quot;)[0].split(&quot;-&quot;)[0]) == 2021 &amp;&amp; (i.ChangeStartTime.split(&quot;T&quot;)[0].split(&quot;-&quot;)[1]) == 10 &amp;&amp; (i.ChangeStartTime.split(&quot;T&quot;)[0].split(&quot;-&quot;)[2]) == 12) ç­›é€‰æ•°æ®ï¼šåœ¨å…ƒæ•°æ®ä¸­ï¼ŒChangeStartTimeå­—æ®µï¼Œå¹´ä»½ä¸º2021å¹´ï¼Œæœˆä»½ä¸º10æœˆï¼Œæ—¥æœŸä¸º12æ—¥çš„æ‰€æœ‰æ•°æ®ã€‚ filterï¼šæ–¹æ³•ç”¨äºè¿‡æ»¤å…ƒç´ ï¼Œfilterçš„ç”¨æ³•å’Œmapç›¸ä¼¼ï¼Œä½†æ˜¯ä¸åŒçš„æ˜¯ï¼Œfilterä¼šæŠŠä¼ å…¥çš„å‡½æ•°ä¾æ¬¡ç”¨äºæ¯ä¸€ä¸ªå…ƒç´ ï¼Œæ ¹æ®è¿”å›å€¼æ˜¯trueæˆ–æ˜¯falseæ¥è¿›è¡Œåˆ¤æ–­æ˜¯ä¿ç•™æˆ–æ˜¯ä¸¢å¼ƒè¯¥å…ƒç´ ã€‚ ğŸš©æ•°æ®å»é‡.map() 123456var deduplication = new Map()dataOrigin.forEach((e) =&gt;&#123; if(!deduplication.has(e.ChangeID))&#123; deduplication.set(e.ChangeID , true) &#125;&#125;) é€šè¿‡.map()æ¥è¿›è¡Œæ•°æ®çš„å»é‡ï¼Œå®šä¹‰ä¸€ä¸ªmapå¯¹è±¡ï¼Œéå†å…ƒæ•°æ®ï¼Œå¯¹mapå¯¹è±¡è¿›è¡Œåˆ¤æ–­ï¼Œå¦‚æœä¸å­˜åœ¨ChangIDï¼ˆå»é‡ä¾æ®ï¼‰ï¼Œé‚£ä¹ˆå°±å°†è¿™ä¸€æ¡æ•°æ®å­˜å…¥mapå¯¹è±¡ä¸­ï¼ŒåŒæ—¶å®Œæˆæ•°æ®çš„è®°å½•ï¼Œå®Œæˆæ•°æ®çš„å»é‡ã€‚ ğŸš©æ—¶é—´æˆ³è½¬æ¢ä¸è®¡ç®— ä¸­å›½æ ‡å‡†æ—¶é—´ï¼šThu Feb 28 2019 17:11:43 GMT+0800 JSé»˜è®¤ä¸­å›½æ ‡å‡†æ—¶é—´æ˜¯ GMTæ—¶é—´.ç”±äºæˆ‘ä»¬å›½å®¶é‡‡ç”¨çš„æ˜¯ä¸œå…«åŒºæ—¶é—´,å› æ­¤æ˜¯GMT +0800 ISO8601æ ‡å‡†æ—¶é—´ï¼š2019-02-28T09:51:45.540Z å…¶ä¸­Tè¡¨ç¤ºåˆå¹¶,Zè¡¨ç¤ºUTCæ—¶é—´ æ—¶é—´æˆ³æ˜¯æŒ‡æ ¼æ—å¨æ²»æ—¶é—´1970å¹´01æœˆ01æ—¥00æ—¶00åˆ†00ç§’(åŒ—äº¬æ—¶é—´1970å¹´01æœˆ01æ—¥08æ—¶00åˆ†00ç§’)èµ·è‡³ç°åœ¨çš„æ€»ç§’æ•°ã€‚javaçš„dateé»˜è®¤ç²¾åº¦æ˜¯æ¯«ç§’ï¼Œä¹Ÿå°±æ˜¯è¯´ç”Ÿæˆçš„æ—¶é—´æˆ³å°±æ˜¯13ä½çš„ï¼Œè€Œåƒc++æˆ–è€…phpç”Ÿæˆçš„æ—¶é—´æˆ³é»˜è®¤å°±æ˜¯10ä½çš„ï¼Œå› ä¸ºå…¶ç²¾åº¦æ˜¯ç§’ã€‚ 12345dataOrigin.forEach((e) =&gt;&#123; var start = new Date(e.ChangeStartTime).getTime() var end = new Date(e.ChangeEndTime).getTime() var tim = parseFloat(end - start) / 1000&#125;) new Date()ï¼šè·å–æ—¶é—´ï¼ŒDateå¯¹è±¡ç”¨äºå¤„ç†æ—¥æœŸå’Œæ—¶é—´; getTime()ï¼šæ–¹æ³•è¿”å›ä»1970 å¹´ 1 æœˆ 1 æ—¥åˆå¤œåˆ°æŒ‡å®šæ—¥æœŸä¹‹é—´çš„æ¯«ç§’æ•°ï¼› parseFloat()ï¼šå‡½æ•°è§£æå­—ç¬¦ä¸²å¹¶è¿”å›æµ®ç‚¹æ•° æè¿°ï¼š ï¼ˆå›¾ç‰‡æ‰¾ä¸åˆ°äº†é¢â€¦â€¦ç­‰æˆ‘ä¿®ä¸€ä¸‹ï¼‰ æ­¤å‡½æ•°ç¡®å®šæŒ‡å®šå­—ç¬¦ä¸²ä¸­çš„ç¬¬ä¸€ä¸ªå­—ç¬¦æ˜¯å¦ä¸ºæ•°å­—ã€‚å¦‚æœæ˜¯ï¼Œå®ƒä¼šè§£æå­—ç¬¦ä¸²ç›´åˆ°åˆ°è¾¾æ•°å­—çš„æœ«å°¾ï¼Œå¹¶å°†æ•°å­—ä½œä¸ºæ•°å­—è€Œä¸æ˜¯å­—ç¬¦ä¸²è¿”å›ã€‚ æ³¨æ„ï¼šåªè¿”å›å­—ç¬¦ä¸²ä¸­çš„ç¬¬ä¸€ä¸ªæ•°å­—ï¼ æ³¨é‡Šï¼šå…è®¸å‰å¯¼å’Œå°¾éšç©ºæ ¼ã€‚ æ³¨é‡Šï¼šå¦‚æœç¬¬ä¸€ä¸ªå­—ç¬¦ä¸èƒ½è½¬æ¢ä¸ºæ•°å­—ï¼ŒparseFloat() è¿”å› NaNã€‚ ğŸš©æ•°æ®keyå¦‚ä½•èµ‹å€¼ä¸ºç©ºåœ¨è¿›è¡Œæ•°æ®å¤„ç†æ—¶ï¼Œä¼šå‡ºç°ä¸åŒçš„å¯¹è±¡å¯¹åº”çš„å€¼ä¸ä¸€æ ·ã€‚ æ¯”å¦‚æ±‚æŸä¸ªè®¾å¤‡å„ä¸ªçŠ¶æ€ä¸‹çš„æŒç»­æ—¶é•¿ï¼Œå¯èƒ½å°±ä¼šå‡ºç°æŸå°è®¾å¤‡æ²¡æœ‰æŸä¸ªçŠ¶æ€ï¼Œé‚£ä¹ˆé€šè¿‡mapå¯¹è±¡setåˆ°çš„æ–¹æ³•ï¼Œå°±ä¸ä¼šæ˜¾ç¤ºè¿™ä¸€ä¸ªçŠ¶æ€çš„ä»»ä½•æ•°æ®ã€‚ é‚£ä¹ˆï¼Œé€šè¿‡æå‰å­˜å…¥map(key &#x3D;&gt; value)ï¼Œå°±å¯ä»¥é¿å…æ­¤é—®é¢˜ï¼Œå¦‚æœå‡ºç°äº†å¯¹åº”æ•°æ®ï¼Œé‚£ä¹ˆåˆ™ä¼šæ˜¾ç¤ºä½ å­˜å…¥çš„æ•°æ®valueã€‚ 12345678var run = new Map()var stand = new Map()var stop = new Map()tmp1.forEach((e) =&gt;&#123; run.set(e.machine , 0) stand.set(e.machine , 0) stop.set(e.machine , 0)&#125;) é€šè¿‡setæå‰å­˜å…¥æ•°æ®ï¼Œmapåˆ™ä¼šå¦‚ä»¥ä¸‹å½¢å¼ï¼Œè¿™æ ·å³ä½¿åœ¨åç»­å¤„ç†ä¸­ï¼ŒæŸå°è®¾å¤‡æ²¡æœ‰æ­¤çŠ¶æ€çš„ä»»ä½•æ•°æ®ï¼Œä¹Ÿä¸ä¼šå¿½ç•¥æ­¤æ¡æ•°æ®ï¼Œè€Œæ˜¯å­˜å…¥äº†ï¼ˆkey &#x3D;&gt; 0ï¼‰æ­¤æ¡æ•°æ®ï¼Œé¿å…äº†åç»­æ‰‹åŠ¨æ’å…¥æ•°æ®çš„éº»çƒ¦ã€‚ map( {machine1 &#x3D;&gt; 0}ï¼Œ {machine2 &#x3D;&gt; 0}ï¼Œ {machine3 &#x3D;&gt; 0}) ğŸš©datasetæ•°æ®é›†ä½¿ç”¨æƒ…å†µç›®å‰æ¥è¯´ï¼Œå”¯ä¸€æ¨èä½¿ç”¨æ•°æ®é›†çš„åœ°æ–¹æ˜¯å¤šæ¡æ•°æ®ã€æ•°æ®æˆè¡¨çš„æ ¼å¼æ•°æ®ã€‚å…¶ä»–æš‚æ—¶ä¸è€ƒè™‘ä½¿ç”¨dataset 123dataset:&#123; source:[data1,data2,data3]&#125; æ•°æ®é›†ï¼š ï¼ˆå›¾ç‰‡æ‰¾ä¸åˆ°äº†é¢â€¦â€¦ç­‰æˆ‘ä¿®ä¸€ä¸‹ï¼‰ data1ä¸ºæ•°æ®å¤´ï¼Œæ•°æ®å¤´åœ¨ç”Ÿæˆå›¾è¡¨åä¸ºå›¾ä¾‹ï¼Œè¯»å–æ•°æ®æ–¹å¼ä¸ºä»ä¸Šåˆ°ä¸‹ï¼› data2ä¸ºæ•°æ®é›†ï¼Œæ•°æ®é›†ä¸­çš„å¤´éƒ¨ä¸ºå›¾è¡¨æ¨ªåæ ‡ï¼› å¦‚æœä¸æ»¡è¶³ä»¥ä¸Šæ¡ä»¶çš„å›¾ï¼Œå»ºè®®ç›´æ¥ç»˜åˆ¶ï¼Œé‡‡ç”¨dataçš„æ–¹å¼å»å¯¼å…¥æ•°æ®ï¼Œè€Œä¸é‡‡ç”¨æ•°æ®é›† ğŸš©å…³äºæ‹¼æ¥æ¯”è¾ƒæ‹¼æ¥æ¯”è¾ƒçš„ç›®çš„æ˜¯å¤„ç†éƒ¨åˆ†å†…å®¹æ•°æ®ï¼Œæ€è·¯æ˜¯å…ˆåœ¨å¤„ç†åæ•°ç»„ä¸­å°†éœ€è¦ä¿ç•™çš„å­—æ®µè¿›è¡Œæ‹¼æ¥ï¼Œç„¶åå¦ä¸€ä¸ªæ–°æ•°ç»„ä¹ŸåŒæ—¶è·å–è¿™ä¸ªæ¯”è¾ƒå­—æ®µï¼ŒåŒæ—¶å¢åŠ æ–°å­—æ®µï¼Œæ–°å­—æ®µå°±æ˜¯æˆ‘ä»¬éœ€è¦å¤„ç†çš„éƒ¨åˆ†å†…å®¹æ•°æ®ï¼Œæ­¤æ—¶ç›¸æ¯”è¾ƒä¸¤ä¸ªæ•°ç»„ï¼Œæ ¹æ®æ•°ç»„çš„å±æ€§ï¼ˆå¦‚å‡ºç°æ¬¡æ•°ï¼Œæ˜¯å¦å­˜åœ¨ï¼‰æ¥å¯¹å†…å®¹æ•°æ®è¿›è¡Œå¤„ç†ï¼ˆå¦‚å¢åˆ æŸ¥æ”¹ï¼Œç´¯åŠ ï¼Œèµ‹å€¼ï¼‰ã€‚ ä¸¾ä¸ªä¾‹å­â‘§ğŸ™‹ğŸŒ°ï¼š æ¯æ—¥å„è½¦é—´å¹³å‡è¿è¡Œæ—¶é•¿ æ­¤æ—¶ï¼Œéœ€è¦æŠ½å–çš„æ•°æ®ä¸ºæ—¥æœŸä¿¡æ¯ï¼Œè½¦é—´ä¿¡æ¯ï¼Œè¿è¡ŒçŠ¶æ€ä¿¡æ¯ï¼Œä»¥åŠæ—¶é•¿æ•°æ®ã€‚éœ€è¦å¤„ç†çš„æ˜¯æ—¶é•¿ï¼Œä½†æ˜¯å¤„ç†çš„æ–¹å¼åªèƒ½æ˜¯ä¸€å¯¹ä¸€ï¼Œæ‰€ä»¥æ­¤æ—¶æˆ‘ä»¬å°†æ—¥æœŸä¿¡æ¯å’Œè½¦é—´ä¿¡æ¯è¿›è¡Œæ‹¼æ¥æ¥å¤„ç†æ—¶é•¿æ•°æ®ã€‚ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950let tempArr = []; for (let i in state.sumda) &#123; let list = state.sumda[i]; if (!(list.ChangeTime &amp;&amp; list.MachineFactory)) &#123; // å¦‚æœ 20GP continue; &#125; else &#123; let compare = &#123; type: list.ChangeTime + &quot; &quot; + list.MachineFactory, &#125;; //ä½œæ¯”è¾ƒçš„å¯¹è±¡ (å› ä¸ºæˆ‘éœ€è¦è¿™ç§æ ¼å¼ï¼Œä½ ä¹Ÿå¯ä»¥è‡ªå®šä¹‰æ ¼å¼) if (tempArr.length == 0) &#123; //è¿™æ®µä»£ç å¿…é¡»è¦å†™ let num = Number(list.times); let cou = Number(list.count); // console.log(num); // console.log(cou); let obj = &#123; type: list.ChangeTime + &quot; &quot; + list.MachineFactory, total: num, count: cou, &#125;; tempArr.push(obj); // console.log(tempArr,&quot;0000000&quot;); &#125; else &#123; let flag = true; for (let j in tempArr) &#123; //è¿™ä¸ªå¾ªç¯åªåšä¸€ä¸ªæ“ä½œï¼Œæœ‰ç›¸åŒç±»å‹çš„å°±è¿›è¡Œç»Ÿè®¡ if (tempArr[j][&quot;type&quot;] == compare.type) &#123; tempArr[j][&quot;total&quot;] += Number(list.times); tempArr[j][&quot;count&quot;] += Number(list.count); flag = false; //å·²ç»ç»Ÿè®¡è¿‡çš„ï¼Œå°±ä¸è¦å†é‡å¤äº† break; &#125; &#125; if (flag) &#123; //å¦‚æœæ²¡æœ‰è¿™ç§ç±»å‹çš„ï¼Œå°±pushè¿›å» let num = Number(list.times); let cou = Number(list.count); var obj = &#123; type: list.ChangeTime + &quot; &quot; + list.MachineFactory, total: num, count: cou, &#125;; tempArr.push(obj); console.log(tempArr); &#125; &#125; &#125; &#125; console.log(tempArr); ğŸš©åˆ é™¤æˆ–æ·»åŠ æŒ‡å®šå…ƒç´ .splice()","categories":["JavaScript"]},{"title":"Hudiæ­å»º","path":"/2024/04/25/hudi-build/","content":"Hudiæ­å»ºMaven è§£å‹æ–‡ä»¶1tar -zxvf /opt/software/apache-maven-3.6.1-bin.tar.gz -C /opt/module/ é…ç½®ç¯å¢ƒå˜é‡1234vi /etc/profile#mavenexport MAVEN_HOME=/opt/module/apache-maven-3.6.1-binexport PATH=$PATH:$MAVEN_HOME/bin æ·»åŠ é˜¿é‡Œé•œåƒ1234567vi /opt/module/maven-3.6.1/conf/settings.xml&lt;mirror&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;&lt;/mirror&gt; ä¿®æ”¹æœ¬åœ°ä»“åº“12vi /opt/module/maven-3.6.1/conf/settings.xml&lt;localRepository&gt;/opt/software/RepMaven&lt;/localRepository&gt; Hudi è§£å‹æ–‡ä»¶1tar -zxvf /opt/software/hudi-0.11.0.src.tgz -C /opt/module/ ä¿®æ”¹POMæ–‡ä»¶ä¿®æ”¹ä¾èµ–ç»„ä»¶ç‰ˆæœ¬123vim /opt/software/hudi-0.12.0/pom.xml&lt;hadoop.version&gt;3.1.3&lt;/hadoop.version&gt;&lt;hive.version&gt;3.1.2&lt;/hive.version&gt; ä¿®æ”¹æºç å…¼å®¹hadoop3.x12vim /opt/software/hudi-0.12.0/hudi-common/src/main/java/org/apache/hudi/common/table/log/block/HoodieParquetDataBlock.javatry(FSDataOutputStream outputStream) = new FSDataOutputStream(baos) åœ¨æ‹¬å·ä¸­åŠ å…¥nullï¼Œä¿®æ”¹åå¦‚ä¸‹ 1try(FSDataOutputStream outputStream) = new FSDataOutputStream(baos,null) ä½ç½®åœ¨æ–‡ä»¶110è¡Œå·¦å³ï¼Œå¯ä»¥ç›´æ¥æœç´¢baosè¿›è¡Œæ“ä½œ hudi-spark-bundleä¿®æ”¹äº†Hiveç‰ˆæœ¬ä¸º3.1.2ï¼Œå…¶æºå¸¦çš„jettyæ˜¯0.9.3ï¼Œhudiæœ¬èº«ç”¨çš„0.9.4ï¼Œå­˜åœ¨ä¾èµ–å†²çªã€‚ä¿®æ”¹hudi-spark-bundleçš„pomæ–‡ä»¶ï¼Œæ’é™¤ä½ç‰ˆæœ¬jettyï¼Œæ·»åŠ hudiæŒ‡å®šç‰ˆæœ¬çš„jettyã€‚ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118vim /opt/software/hudi-0.12.0/packaging/hudi-spark-bundle/pom.xml&lt;!-- Hive --&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;hive.groupid&#125;&lt;/groupId&gt; &lt;artifactId&gt;hive-service&lt;/artifactId&gt; &lt;version&gt;$&#123;hive.version&#125;&lt;/version&gt; &lt;scope&gt;$&#123;spark.bundle.hive.scope&#125;&lt;/scope&gt; //hive-serviceæ·»åŠ å†…å®¹ &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.pentaho&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;hive.groupid&#125;&lt;/groupId&gt; &lt;artifactId&gt;hive-service-rpc&lt;/artifactId&gt; &lt;version&gt;$&#123;hive.version&#125;&lt;/version&gt; &lt;scope&gt;$&#123;spark.bundle.hive.scope&#125;&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;hive.groupid&#125;&lt;/groupId&gt; &lt;artifactId&gt;hive-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;hive.version&#125;&lt;/version&gt; &lt;scope&gt;$&#123;spark.bundle.hive.scope&#125;&lt;/scope&gt; //hive-jdbcæ·»åŠ å†…å®¹ &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;hive.groupid&#125;&lt;/groupId&gt; &lt;artifactId&gt;hive-metastore&lt;/artifactId&gt; &lt;version&gt;$&#123;hive.version&#125;&lt;/version&gt; &lt;scope&gt;$&#123;spark.bundle.hive.scope&#125;&lt;/scope&gt; //hive-metastoreæ·»åŠ å†…å®¹ &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.datanucleus&lt;/groupId&gt; &lt;artifactId&gt;datanucleus-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;hive.groupid&#125;&lt;/groupId&gt; &lt;artifactId&gt;hive-common&lt;/artifactId&gt; &lt;version&gt;$&#123;hive.version&#125;&lt;/version&gt; &lt;scope&gt;$&#123;spark.bundle.hive.scope&#125;&lt;/scope&gt; //hive-commonæ·»åŠ å†…å®¹ &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.eclipse.jetty.orbit&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; &lt;!-- å¢åŠ hudié…ç½®ç‰ˆæœ¬çš„jetty --&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-server&lt;/artifactId&gt; &lt;version&gt;$&#123;jetty.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-util&lt;/artifactId&gt; &lt;version&gt;$&#123;jetty.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-webapp&lt;/artifactId&gt; &lt;version&gt;$&#123;jetty.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-http&lt;/artifactId&gt; &lt;version&gt;$&#123;jetty.version&#125;&lt;/version&gt; &lt;/dependency&gt; hudi-utilities-bundleä¿®æ”¹hudi-utilities-bundleçš„pomæ–‡ä»¶ï¼Œæ’é™¤ä½ç‰ˆæœ¬jettyï¼Œæ·»åŠ hudiæŒ‡å®šç‰ˆæœ¬çš„jetty 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149vim /opt/software/hudi-0.12.0/packaging/hudi-utilities-bundle/pom.xml &lt;!-- Hoodie --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hudi&lt;/groupId&gt; &lt;artifactId&gt;hudi-common&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; //hudi-commonæ·»åŠ å†…å®¹ &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hudi&lt;/groupId&gt; &lt;artifactId&gt;hudi-client-common&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; //hudi-client-commonæ·»åŠ å†…å®¹ &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- Hive --&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;hive.groupid&#125;&lt;/groupId&gt; &lt;artifactId&gt;hive-service&lt;/artifactId&gt; &lt;version&gt;$&#123;hive.version&#125;&lt;/version&gt; &lt;scope&gt;$&#123;utilities.bundle.hive.scope&#125;&lt;/scope&gt; //hive-serviceæ·»åŠ å†…å®¹ &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;servlet-api&lt;/artifactId&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.pentaho&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;hive.groupid&#125;&lt;/groupId&gt; &lt;artifactId&gt;hive-service-rpc&lt;/artifactId&gt; &lt;version&gt;$&#123;hive.version&#125;&lt;/version&gt; &lt;scope&gt;$&#123;utilities.bundle.hive.scope&#125;&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;hive.groupid&#125;&lt;/groupId&gt; &lt;artifactId&gt;hive-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;hive.version&#125;&lt;/version&gt; &lt;scope&gt;$&#123;utilities.bundle.hive.scope&#125;&lt;/scope&gt; //hive-jdbcæ·»åŠ å†…å®¹ &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;hive.groupid&#125;&lt;/groupId&gt; &lt;artifactId&gt;hive-metastore&lt;/artifactId&gt; &lt;version&gt;$&#123;hive.version&#125;&lt;/version&gt; &lt;scope&gt;$&#123;utilities.bundle.hive.scope&#125;&lt;/scope&gt; //hive-metastoreæ·»åŠ å†…å®¹ &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.datanucleus&lt;/groupId&gt; &lt;artifactId&gt;datanucleus-core&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;hive.groupid&#125;&lt;/groupId&gt; &lt;artifactId&gt;hive-common&lt;/artifactId&gt; &lt;version&gt;$&#123;hive.version&#125;&lt;/version&gt; &lt;scope&gt;$&#123;utilities.bundle.hive.scope&#125;&lt;/scope&gt;ã€ //hive-commonæ·»åŠ å†…å®¹ &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.eclipse.jetty.orbit&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- å¢åŠ hudié…ç½®ç‰ˆæœ¬çš„jetty --&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-server&lt;/artifactId&gt; &lt;version&gt;$&#123;jetty.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-util&lt;/artifactId&gt; &lt;version&gt;$&#123;jetty.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-webapp&lt;/artifactId&gt; &lt;version&gt;$&#123;jetty.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-http&lt;/artifactId&gt; &lt;version&gt;$&#123;jetty.version&#125;&lt;/version&gt; &lt;/dependency&gt; æ‰§è¡Œç¼–è¯‘å‘½ä»¤ æ‰“åŒ…å‘½ä»¤ 12mvn clean package-DskipTests -Dspark3.1 -Dflink1.14 -Dscala-2.12 -Dhadoop.version=3.1.3 -Pflink-bundle-shade-hive3 -DskipTestsï¼Œä¸æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹ï¼Œä½†ç¼–è¯‘æµ‹è¯•ç”¨ä¾‹ç±»ç”Ÿæˆç›¸åº”çš„classæ–‡ä»¶è‡³target&#x2F;test-classesä¸‹ã€‚ -Dmaven.test.skip&#x3D;trueï¼Œä¸æ‰§è¡Œæµ‹è¯•ç”¨ä¾‹ï¼Œä¹Ÿä¸ç¼–è¯‘æµ‹è¯•ç”¨ä¾‹ç±»ã€‚ -Dspark\t-Dflink\t-Dscala\tä¸ºå¯¹åº”ç»„ä»¶çš„ç‰ˆæœ¬ -Pflink-bundle-shade-hive3\tå¦‚æœä¸æŒ‡å®šæ­¤æ¡ï¼Œä¼šåœ¨hudiç¼–è¯‘æ—¶å¯¹flink-bundleçš„æ¶åŒ…æŠ¥é”™ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œhudiçš„ç¼–è¯‘å‘½ä»¤éœ€è¦åœ¨hudiçš„æ ¹ç›®å½•ä¸‹è¿›è¡Œæ‰§è¡Œ è¿è¡Œæ¡ˆä¾‹ç§»åŠ¨jaråŒ…æˆ‘ä»¬ç¼–è¯‘å¥½çš„jaråŒ…å­˜å‚¨åœ¨hudiæ ¹ç›®å½•ä¸‹çš„packagingä¸­ï¼Œæˆ‘ä»¬éœ€è¦è¿›å…¥packagingæ–‡ä»¶å¤¹æ‰¾åˆ°hudi-spark3.1-bundle_2.12-0.11.0.jaræ¶åŒ…å³å¯ã€‚ 1cd /opt/module/hudi-0.11.0/packaging/hudi-spark-bundle/targe éšåç§»åŠ¨æ¶åŒ…åˆ°sparkç›®å½•ä¸‹çš„jarsæ–‡ä»¶å¤¹ä¸­ 1cp /opt/module/hudi-0.11.0/packaging/hudi-spark-bundle/target/hudi-spark3.1-bundle_2.12-0.11.0 /opt/module/spark-3.1.1-bin-hadoop3.2/jars/ è¿›å…¥spark-shell123spark-shell \\--conf &#x27;spark.serializer=org.apache.spark.serializer.KryoSerializer&#x27; \\--conf &#x27;spark.sql.extensions=org.apache.spark.sql.hudi.HoodieSparkSessionExtension&#x27; \\ â€“conf â€˜spark.serializer&#x3D;org.apache.spark.serializer.KryoSerializerâ€™\tåºåˆ—åŒ– â€“conf â€˜spark.sql.extensions&#x3D;org.apache.spark.sql.hudi.HoodieSparkSessionExtensionâ€™\té›†æˆspark è¿è¡Œæ¡ˆä¾‹1234567891011121314151617181920212223242526import org.apache.hudi.QuickstartUtils._import scala.collection.JavaConversions._import org.apache.spark.sql.SaveMode._import org.apache.hudi.DataSourceReadOptions._import org.apache.hudi.DataSourceWriteOptions._import org.apache.hudi.config.HoodieWriteConfig._import org.apache.hudi.common.model.HoodieRecord val tableName = &quot;hudi_trips_cow&quot;val basePath = &quot;file:///tmp/hudi_trips_cow&quot;val dataGen = new DataGenerator val inserts = convertToStringList(dataGen.generateInserts(10))val df = spark.read.json(spark.sparkContext.parallelize(inserts, 2))df.write.format(&quot;hudi&quot;). options(getQuickstartWriteConfigs). option(PRECOMBINE_FIELD_OPT_KEY, &quot;ts&quot;). option(RECORDKEY_FIELD_OPT_KEY, &quot;uuid&quot;). option(PARTITIONPATH_FIELD_OPT_KEY, &quot;partitionpath&quot;). option(TABLE_NAME, tableName). mode(Overwrite). save(basePath) val tripsSnapshotDF = spark.read.format(&quot;hudi&quot;).load(basePath + &quot;/*/*/*/*&quot;)tripsSnapshotDF.createOrReplaceTempView(&quot;hudi_trips_snapshot&quot;)spark.sql(&quot;select fare, begin_lon, begin_lat, ts from hudi_trips_snapshot where fare &gt; 20.0&quot;).show() ç»“æœ æ¡ˆä¾‹ç»“æœå›¾","categories":["Hudi"]}]